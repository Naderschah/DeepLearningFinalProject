{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication\n",
    "\n",
    "I cant find model weights, only the layers of the final quanitzed model \n",
    "\n",
    "Instead I will replicate the architecture and the way training data was split etc\n",
    "\n",
    "Training Input is everything except classification\n",
    "\n",
    "Data is scaled in the following ways:\n",
    "- pT ([:,:,0]) Is z-scaled (x - mean)/std : They say they bring all to O(1) but not how so this seems reasonable\n",
    "- eta and phi are tanh scaled : tanh(x / x_b) where x_b is the max(abs(x)) for non padded entries : This is only done before the MSE loss, implementing this for KL is very non trivial \n",
    "\n",
    "Models are constructed as classes with the encoder and decoder created as submodels\n",
    "\n",
    "So if we have a full model say CNN_VAE we access the encoder with either CNN_VAE.layers[0] or CNN_VAE.get_layer(\"cnn_encoder\"), but check what the actual name is, the submodel extracted then has the same methods available\n",
    "\n",
    "The MSE loss and masked MSE loss is handled as functions that require a partial to work due to the way tensorflow works\n",
    "\n",
    "The beta parameter managing the balance between MSE and KL is not defined in the paper -> A number of values are trialed and the best is selected -> Note that this is non exhaustive of a search and only done to order of magnitude not to exact value\n",
    "\n",
    "Also note that if you run this and an error occurs during any step whatsoever you will likely have to restart the kernel as I am now convinced that this causes Memory leaks either due to jupyter loosing the reference or tensorflow handling the reference in an odd fashion -> I would like to blame tensorflow rather than jupyter\n",
    "\n",
    "Misc Notes:\n",
    "\n",
    "When you inevitably run into nan errors dont bother printing things use tf.debugging.enable_check_numerics() instead, this will tell the compiler to raise an exception on nan and inf with a full backtrace on which layer this occured, look for a long / seperated string that contains layer and operation names it essentially gives you the location, if its not clear copy paste with the model architecture to chatGPT it will usually identify the location (allthough it really likes quoting the obvious reasons nan may arrise that have nothing to do with the current problem)\n",
    "\n",
    "For debugging print works when not compiled, tf.print works when compiled, i always just do both and that works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 09:08:45.428548: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-13 09:08:45.819145: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-13 09:08:47.385736: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# Loss Functions --- Reasoning written out where data is loaded -> Partial needs to be called on these \n",
    "import tensorflow as tf\n",
    "@tf.function\n",
    "def scale_for_MSE(y_true, y_pred, eta_b, phi_b):\n",
    "    \"\"\"\n",
    "    Loss scaling helper\n",
    "    \"\"\"\n",
    "    # Extract\n",
    "    eta_true = y_true[:, :, 1]\n",
    "    phi_true = y_true[:, :, 2]\n",
    "    eta_pred = y_pred[:, :, 1]\n",
    "    phi_pred = y_pred[:, :, 2]\n",
    "    # Apply tanh scaling\n",
    "    eta_true_scaled = tf.tanh(eta_true / eta_b)\n",
    "    phi_true_scaled = tf.tanh(phi_true / phi_b)\n",
    "    eta_pred_scaled = tf.tanh(eta_pred / eta_b)\n",
    "    phi_pred_scaled = tf.tanh(phi_pred / phi_b)\n",
    "    # Replace and hope compilation makes this efficient\n",
    "    y_true_scaled = tf.concat([\n",
    "        y_true[:, :, :1],                           \n",
    "        eta_true_scaled[:, :, tf.newaxis],          \n",
    "        phi_true_scaled[:, :, tf.newaxis],          \n",
    "        y_true[:, :, 3:],                           \n",
    "    ], axis=-1)\n",
    "\n",
    "    y_pred_scaled = tf.concat([\n",
    "        y_pred[:, :, :1],\n",
    "        eta_pred_scaled[:, :, tf.newaxis],\n",
    "        phi_pred_scaled[:, :, tf.newaxis],\n",
    "        y_pred[:, :, 3:],\n",
    "    ], axis=-1)\n",
    "    return y_true_scaled, y_pred_scaled\n",
    "\n",
    "@tf.function\n",
    "def full_MSE(y_true, y_pred, eta_b, phi_b):\n",
    "    \"Full Loss Function overwrite\"\n",
    "    y_true_scaled, y_pred_scaled = scale_for_MSE(y_true, y_pred, eta_b, phi_b)\n",
    "    # Compute MSE \n",
    "    mse = tf.reduce_mean(\n",
    "        tf.reduce_sum(tf.square(y_true_scaled - y_pred_scaled), axis=(1, 2))\n",
    "    )\n",
    "    \n",
    "    return mse\n",
    "\n",
    "def masked_mse(y_true_og, y_pred_og, eta_b, phi_b, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Computes MSE per event, ignoring any zero-padded rows.\n",
    "    Assumes y_true, y_pred each have shape (batch, n_features)\n",
    "    or possibly (batch, H, W, C). Adjust logic as needed.\n",
    "    \"\"\"\n",
    "    y_true, y_pred = scale_for_MSE(y_true_og, y_pred_og, eta_b, phi_b)\n",
    "    # Sum over feature-dims to see whether row is all zeros\n",
    "    row_sum = tf.reduce_sum(tf.abs(y_true), axis=-1)  # shape = (batch,)\n",
    "    # A mask: 1 if non-padded, 0 if padded\n",
    "    mask = tf.cast(row_sum > epsilon, tf.float32)\n",
    "    # Squared error, summation over features\n",
    "    sq_error = tf.reduce_sum(tf.square(y_true - y_pred), axis=-1)  # shape=(batch,)\n",
    "    # Apply mask -> I hate this\n",
    "    sq_error_masked = sq_error * mask\n",
    "    return tf.reduce_sum(sq_error_masked) / tf.reduce_sum(mask)\n",
    "\n",
    "def tmp():\n",
    "    \"\"\"For VAE implementation a lot of code is taken from \n",
    "    https://keras.io/examples/generative/vae/\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    import keras\n",
    "    from keras import ops\n",
    "    from keras import layers\n",
    "    class Sampling(layers.Layer):\n",
    "        \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "\n",
    "        def call(self, inputs):\n",
    "            z_mean, z_log_var = inputs\n",
    "            batch = ops.shape(z_mean)[0]\n",
    "            dim = ops.shape(z_mean)[1]\n",
    "            epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)\n",
    "            return z_mean + ops.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "    return Sampling\n",
    "Sampling = tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DNN_Encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"DNN_Encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_in (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ latent (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,435</span> (9.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,435\u001b[0m (9.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,435</span> (9.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,435\u001b[0m (9.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DNN_Decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"DNN_Decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reconstruction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,881</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder_in (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reconstruction (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)             │         \u001b[38;5;34m1,881\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,681</span> (10.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,681\u001b[0m (10.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,585</span> (10.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,585\u001b[0m (10.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def dnn_reshape():\n",
    "    \"\"\"Input Space for DNN is flattened\"\"\"\n",
    "    return layers.Flatten()\n",
    "\n",
    "def dnn_encoder(input_dim = 57, latent_dim = 3, name='DNN_Encoder', vae=False):\n",
    "    inputs = tf.keras.Input(shape=(19,3,), name=\"encoder_in\")\n",
    "    x = inputs#layers.BatchNormalization()(inputs)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(32)(x) # Activation is None By Default\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dense(16)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    if vae:\n",
    "        z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "        # Kernel initializer as this term is exponentiated and default init makes the exp -> ooo\n",
    "        z_log_var = layers.Dense(latent_dim, name=\"z_log_var\", kernel_initializer=\"zeros\")(x)\n",
    "        z = Sampling()([z_mean, z_log_var])\n",
    "        return Model(inputs, [z_mean, z_log_var, z], name=name)\n",
    "\n",
    "    latent = layers.Dense(latent_dim, name=\"latent\")(x)\n",
    "\n",
    "    return Model(inputs, latent, name=name)\n",
    "\n",
    "def dnn_decoder(output_dim=57, latent_dim=3, name='DNN_Decoder'):\n",
    "    \"\"\"\n",
    "    BN between Fully connected and activation, last doesnt have activation & BN\n",
    "    \"\"\"\n",
    "    latent_in = tf.keras.Input(shape=(latent_dim,), name=\"decoder_in\")\n",
    "\n",
    "    y = layers.Dense(16)(latent_in)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "\n",
    "    y = layers.Dense(32)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "\n",
    "    outputs = layers.Dense(output_dim, name=\"reconstruction\")(y)\n",
    "\n",
    "    # And reshape so that the loss works right\n",
    "    outputs = layers.Reshape((19,3,))(outputs)\n",
    "\n",
    "    return Model(latent_in, outputs, name=name)\n",
    "\n",
    "dnn_encoder().summary()\n",
    "dnn_decoder().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DNN_AE(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    AE = Encoder -> Decoder, no sampling.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=57, latent_dim=3):\n",
    "        super().__init__()\n",
    "        self.encoder = dnn_encoder(input_dim=input_dim, latent_dim=latent_dim)\n",
    "        self.decoder = dnn_decoder(output_dim=input_dim, latent_dim=latent_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        z = self.encoder(x)            # shape=(batch, latent_dim)\n",
    "        x_recon = self.decoder(z)      # shape=(batch, input_dim)\n",
    "        return x_recon\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DNN_VAE(tf.keras.Model):\n",
    "    def __init__(self, eta_b, phi_b, input_dim=57, latent_dim=3, beta=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = dnn_encoder(input_dim=input_dim, latent_dim=latent_dim, vae=True)\n",
    "        self.decoder = dnn_decoder(output_dim=input_dim, latent_dim=latent_dim)\n",
    "        self.beta = beta\n",
    "        self.eta_b = eta_b\n",
    "        self.phi_b = phi_b\n",
    "        \n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                masked_mse(data, reconstruction, self.eta_b, self.phi_b)\n",
    "            )\n",
    "\n",
    "            # ✅ KL divergence\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "\n",
    "            # ✅ Total loss with β weighting\n",
    "            total_loss = (1.0 - self.beta) * reconstruction_loss + self.beta * kl_loss\n",
    "\n",
    "        # ✅ Backpropagation\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        # ✅ Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cnn_encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ cnn_encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ zero_padding2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ cnn_encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ zero_padding2d (\u001b[38;5;33mZeroPadding2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │             \u001b[38;5;34m4\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ latent (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,948</span> (7.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,948\u001b[0m (7.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,946</span> (7.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,946\u001b[0m (7.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cnn_decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ cnn_decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ zero_padding2d_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ zero_padding2d_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">145</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ cnn_decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m3,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ zero_padding2d_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ zero_padding2d_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │           \u001b[38;5;34m145\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,377</span> (21.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,377\u001b[0m (21.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,377</span> (21.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,377\u001b[0m (21.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_cnn_encoder(name='cnn_encoder', vae=False):\n",
    "    \"\"\"\n",
    "    Build CNN Encoder\n",
    "    vae : Variational Autoencoder varitation (second final layer)\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(19,3,1), name=\"cnn_encoder_input\")\n",
    "    #      Zeropad to (20,3,1)  - Syntax padding = ((top, bottom), (left, right))\n",
    "    x = layers.ZeroPadding2D(padding=((1,0),(0,0)))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    #      Block 1  -> Padding valid means no padding\n",
    "    x = layers.Conv2D(16, kernel_size=(3,3), strides=(1,1), padding='valid', use_bias=False)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.AveragePooling2D(pool_size=(3,1), strides=(3,1))(x)\n",
    "    #      Block 2\n",
    "    x = layers.Conv2D(32, kernel_size=(3,1), strides=(1,1), padding='valid', use_bias=False)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.AveragePooling2D(pool_size=(3,1), strides=(3,1))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    #      Block 3 - started\n",
    "    if vae:\n",
    "        latent_mean = layers.Dense(8, activation=None, name=\"latent_mean\")(x)\n",
    "        latent_log_var = layers.Dense(8, activation=None, name=\"latent_log_var\", kernel_initializer='zeros')(x)\n",
    "        z = Sampling()([latent_mean, latent_log_var])\n",
    "        return tf.keras.Model(inputs, [latent_mean, latent_log_var, z], name=name)\n",
    "\n",
    "    latent = layers.Dense(8, activation=None, name=\"latent\")(x)\n",
    "    return tf.keras.Model(inputs, latent, name=name)\n",
    "\n",
    "\n",
    "def build_cnn_decoder(name='cnn_decoder'):\n",
    "    \"\"\"\n",
    "    CNN decoder from the paper's bottom figure. \n",
    "    Takes a latent dimension (8) -> Dense -> Reshape -> Conv2DTranspose or Upsampling + Conv2D \n",
    "    to go back to shape (20,3,1) then maybe slice off padding if you want 19,3,1 final.\n",
    "    \"\"\"\n",
    "    #      Block 3 - remainder > Forming encoder input \n",
    "    latent_inputs = tf.keras.Input(shape=(8,), name=\"cnn_decoder_input\")\n",
    "    y = layers.Dense(64, activation=None)(latent_inputs) \n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Reshape((2,1,32))(y)\n",
    "    #      Block 4\n",
    "    y = layers.Conv2D(32, kernel_size=(3,1), strides=(1,1), padding='same')(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.UpSampling2D(size=(3,1))(y)\n",
    "    y = layers.ZeroPadding2D(padding=((0,0),(1,1)))(y)\n",
    "    #      Block 5\n",
    "    y = layers.Conv2D(16, kernel_size=(3,1), strides=(1,1), padding='same')(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.UpSampling2D(size=(3,1))(y)\n",
    "    y = layers.ZeroPadding2D(padding=((1,0),(0,0)))(y)\n",
    "    #      Output \n",
    "    output = layers.Conv2D(1, kernel_size=(3,3), strides=(1,1), padding='same')(y)\n",
    "\n",
    "    return tf.keras.Model(latent_inputs, output, name=name)\n",
    "\n",
    "build_cnn_encoder().summary()\n",
    "build_cnn_decoder().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class CNN_AE(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = build_cnn_encoder(name=\"cnn_encoder\")\n",
    "        self.decoder = build_cnn_decoder(name=\"cnn_decoder\")\n",
    "\n",
    "    def call(self, x):\n",
    "        z = self.encoder(x)\n",
    "        recon = self.decoder(z)\n",
    "        return recon\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class CNN_VAE(tf.keras.Model):\n",
    "    def __init__(self,eta_b, phi_b, input_shape=(19, 3, 1), latent_dim=3, beta=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = build_cnn_encoder(vae=True)\n",
    "        self.decoder = build_cnn_decoder()\n",
    "        self.beta = beta\n",
    "        self.eta_b = eta_b\n",
    "        self.phi_b = phi_b\n",
    "        \n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Custom train step\n",
    "        We do the normal thing\n",
    "        But also add the KL divergence term        \n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "\n",
    "            # MSE over all spatial and channel dimensions\n",
    "            #reconstruction_loss = tf.reduce_mean(\n",
    "            #    tf.reduce_sum(tf.square(data - reconstruction), axis=(1, 2, 3))\n",
    "            #)\n",
    "            reconstruction_loss = full_MSE(data , reconstruction[:,:,:,0], self.eta_b, self.phi_b)\n",
    "\n",
    "            # KL divergence term\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "\n",
    "            # Total loss with β weighting\n",
    "            total_loss = (1.0 - self.beta) * reconstruction_loss + self.beta * kl_loss\n",
    "\n",
    "        # Backprop\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        # Update\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Load Data + Define training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "# If you use the dockerfile this should just work \n",
    "dset = h5py.File('/Code/Dataset/background_for_training.h5', 'r')\n",
    "dset = {key: dset[key][()] for key in dset.keys()}\n",
    "\"\"\"\n",
    "Contains keys:\n",
    "    Particles_Classes : 4 classes of Particles\n",
    "    Particles_Names : Names of the Particles\n",
    "    Particles : The data (n, 19,4)\n",
    "        19 : Indexes are\n",
    "            - 0 : Missing Transverse Energy\n",
    "            - 1:4 Up to 4 electrons\n",
    "            - 4:8 Up to 4 muons\n",
    "            - 8-18 Up to 10 jets\n",
    "        Subdimension 4 by idx:\n",
    "            - 0 : pT (transverse momentum)\n",
    "            - 1 : eta (pseudorapidity)\n",
    "            - 2 : phi (azimuthal angle)\n",
    "            - 3 : class (0=Nothing, 1=Met,2=electron,3=muon,4=jet)\n",
    "And when something doesnt make sense (ie [:,0,1:4]) its just zero \n",
    "\"\"\"\n",
    "data = dset['Particles']\n",
    "del dset\n",
    "# Do z score norm to aid in training : They dont specify how they made O(1) : And I assume they mean across all defined objects\n",
    "detected_bmap = (data[:,:,3] != 0) # Select defined entries\n",
    "mean_pt = tf.reduce_mean(data[detected_bmap, 0])\n",
    "std_pt = tf.math.reduce_std(data[detected_bmap, 0])\n",
    "data[:,:,0] = ((data[:,:,0] - mean_pt) / std_pt)\n",
    "\n",
    "\"\"\"\n",
    "They mention in the paper:\n",
    "To account for physical boundaries of η and φ, for those features a re-scaled tanh activation is used in the loss computation.\n",
    "\n",
    "So I assume this means we need to find the extent of the parameters (call it b ) and do tanh(x/b) prior to the loss function, \n",
    "I am not sure how one would go about implementing this for KL loss so Im going to do MSE only \n",
    "\"\"\"\n",
    "eta_b = np.maximum(np.max(data[detected_bmap, 1]), np.abs(np.min(data[detected_bmap, 1]))).astype(\"float32\")\n",
    "phi_b = np.maximum(np.max(data[detected_bmap, 2]), np.abs(np.min(data[detected_bmap, 2]))).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "train_split = int(0.5*len(data))\n",
    "val_split = int((0.4+0.5)*len(data))\n",
    "\n",
    "n = np.arange(len(data)) \n",
    "np.random.shuffle(n)\n",
    "# Do splitting - Dont grab class indices\n",
    "train = data[n[:train_split],          :, :3]\n",
    "val   = data[n[train_split:val_split], :, :3]\n",
    "test  = data[n[val_split:],            :, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def train_dnn_ae(x_train, x_val, epochs=100, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Create and train\n",
    "    \"\"\"\n",
    "    # Build \n",
    "    dnn_ae = DNN_AE(\n",
    "        input_dim=57, latent_dim=3\n",
    "        )\n",
    "\n",
    "    # Compile with Adam and masked MSE\n",
    "    loss_func = tf.function(partial(masked_mse, eta_b=eta_b, phi_b=phi_b))\n",
    "    dnn_ae.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(), \n",
    "        loss=loss_func\n",
    "    )\n",
    "    # Make Callback\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=10, restore_best_weights=True # restore???\n",
    "        )\n",
    "    ]\n",
    "    # Fit \n",
    "    dnn_ae.fit(\n",
    "        x_train, x_train,\n",
    "        validation_data=(x_val, x_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return dnn_ae\n",
    "\n",
    "def train_dnn_vae(x_train, x_val, epochs=100, batch_size=1024, beta=1.0):\n",
    "    \"\"\"\n",
    "    Create and train\n",
    "    \"\"\"\n",
    "    # Build \n",
    "    dnn_vae = DNN_VAE(eta_b=eta_b, phi_b=phi_b, input_dim=57, latent_dim=3, beta=beta)\n",
    "\n",
    "    # Compile with Adam and masked MSE\n",
    "    loss_func = tf.function(partial(masked_mse, eta_b=eta_b, phi_b=phi_b))\n",
    "    dnn_vae.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0), \n",
    "        loss=loss_func\n",
    "    )\n",
    "    # Make Callback\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=10, restore_best_weights=True # restore???\n",
    "        )\n",
    "    ]\n",
    "    # Fit \n",
    "    dnn_vae.fit(\n",
    "        x_train, # It doesnt have y apparently its passed to train_step as (x, y) and then autoresolved to be *(x, y) for val it does need two I do not quite get why\n",
    "        validation_data=(x_val,x_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return dnn_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def train_cnn_ae(x_train, x_val, epochs=100, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Create and train\n",
    "    \"\"\"\n",
    "    cnn_ae_model = CNN_AE(\n",
    "        # No Args\n",
    "    )\n",
    "    loss_func = tf.function(partial(full_MSE, eta_b=eta_b, phi_b=phi_b))\n",
    "    cnn_ae_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=loss_func \n",
    "    )\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=10, restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "    cnn_ae_model.fit(\n",
    "        x_train, x_train,\n",
    "        validation_data=(x_val, x_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    return cnn_ae_model\n",
    "\n",
    "def train_cnn_vae(x_train, x_val, epochs=100, batch_size=1024, beta=1.0):\n",
    "    \"\"\"\n",
    "    Create and train\n",
    "    \"\"\"\n",
    "    cnn_vae_model = CNN_VAE( eta_b=eta_b, phi_b=phi_b, beta=beta )\n",
    "    cnn_vae_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss='mse' # I think this is just ignored since we have a custom train loop\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=10, restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "    cnn_vae_model.fit(\n",
    "        x_train,\n",
    "        validation_data=(x_val, x_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    return cnn_vae_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Training \n",
    "\n",
    "Note that there is a lot of duplicate code as the kernel often doesnt survive past more than one model trainings\n",
    "\n",
    "Also the saving\n",
    "\n",
    "It wants me to implement a get_config method for saving the model, I dont want to do that as this means it will also want me to make a load config and the probably 20 other things\n",
    "\n",
    "I just create a new uncompiled model copy the weigths over save that (and we only really need it to save those anyway) and that should be directly loadable, also it doesnt like hdf5 for saving anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 14ms/step - loss: 0.1535 - val_loss: 0.0763\n",
      "Epoch 2/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - loss: 0.0741 - val_loss: 0.0664\n",
      "Epoch 3/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - loss: 0.0658 - val_loss: 0.0643\n",
      "Epoch 4/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - loss: 0.0640 - val_loss: 0.0630\n",
      "Epoch 5/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - loss: 0.0628 - val_loss: 0.0625\n",
      "Epoch 6/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - loss: 0.0618 - val_loss: 0.0610\n",
      "Epoch 7/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - loss: 0.0611 - val_loss: 0.0624\n",
      "Epoch 8/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0606 - val_loss: 0.0602\n",
      "Epoch 9/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0603 - val_loss: 0.0599\n",
      "Epoch 10/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0599 - val_loss: 0.0599\n",
      "Epoch 11/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - loss: 0.0597 - val_loss: 0.0594\n",
      "Epoch 12/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0593 - val_loss: 0.0595\n",
      "Epoch 13/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - loss: 0.0592 - val_loss: 0.0590\n",
      "Epoch 14/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0591 - val_loss: 0.0586\n",
      "Epoch 15/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0585 - val_loss: 0.0597\n",
      "Epoch 16/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0580 - val_loss: 0.0578\n",
      "Epoch 17/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0576 - val_loss: 0.0574\n",
      "Epoch 18/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0570 - val_loss: 0.0564\n",
      "Epoch 19/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0565 - val_loss: 0.0559\n",
      "Epoch 20/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - loss: 0.0560 - val_loss: 0.0556\n",
      "Epoch 21/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0557 - val_loss: 0.0552\n",
      "Epoch 22/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0556 - val_loss: 0.0550\n",
      "Epoch 23/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0553 - val_loss: 0.0547\n",
      "Epoch 24/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0547 - val_loss: 0.0541\n",
      "Epoch 25/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - loss: 0.0540 - val_loss: 0.0538\n",
      "Epoch 26/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0535 - val_loss: 0.0531\n",
      "Epoch 27/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0529 - val_loss: 0.0530\n",
      "Epoch 28/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0525 - val_loss: 0.0525\n",
      "Epoch 29/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0524 - val_loss: 0.0517\n",
      "Epoch 30/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0520 - val_loss: 0.0524\n",
      "Epoch 31/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0518 - val_loss: 0.0515\n",
      "Epoch 32/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0516 - val_loss: 0.0517\n",
      "Epoch 33/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0514 - val_loss: 0.0516\n",
      "Epoch 34/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - loss: 0.0513 - val_loss: 0.0512\n",
      "Epoch 35/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0511 - val_loss: 0.0510\n",
      "Epoch 36/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0508 - val_loss: 0.0506\n",
      "Epoch 37/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0507 - val_loss: 0.0505\n",
      "Epoch 38/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0505 - val_loss: 0.0504\n",
      "Epoch 39/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0505 - val_loss: 0.0501\n",
      "Epoch 40/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0502 - val_loss: 0.0501\n",
      "Epoch 41/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - loss: 0.0500 - val_loss: 0.0498\n",
      "Epoch 42/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0499 - val_loss: 0.0500\n",
      "Epoch 43/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0498 - val_loss: 0.0499\n",
      "Epoch 44/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0498 - val_loss: 0.0496\n",
      "Epoch 45/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - loss: 0.0496 - val_loss: 0.0503\n",
      "Epoch 46/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7ms/step - loss: 0.0495 - val_loss: 0.0498\n",
      "Epoch 47/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: 0.0495 - val_loss: 0.0495\n",
      "Epoch 48/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - loss: 0.0494 - val_loss: 0.0496\n",
      "Epoch 49/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - loss: 0.0494 - val_loss: 0.0497\n",
      "Epoch 50/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - loss: 0.0492 - val_loss: 0.0496\n",
      "Epoch 51/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 7ms/step - loss: 0.0491 - val_loss: 0.0512\n",
      "Epoch 52/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0492 - val_loss: 0.0497\n",
      "Epoch 53/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7ms/step - loss: 0.0491 - val_loss: 0.0488\n",
      "Epoch 54/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7ms/step - loss: 0.0489 - val_loss: 0.0580\n",
      "Epoch 55/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - loss: 0.0489 - val_loss: 0.0488\n",
      "Epoch 56/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - loss: 0.0488 - val_loss: 0.0489\n",
      "Epoch 57/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 7ms/step - loss: 0.0488 - val_loss: 0.0484\n",
      "Epoch 58/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 8ms/step - loss: 0.0489 - val_loss: 0.0487\n",
      "Epoch 59/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 7ms/step - loss: 0.0488 - val_loss: 0.0486\n",
      "Epoch 60/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - loss: 0.0486 - val_loss: 0.0489\n",
      "Epoch 61/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - loss: 0.0486 - val_loss: 0.0481\n",
      "Epoch 62/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - loss: 0.0486 - val_loss: 0.0483\n",
      "Epoch 63/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0487 - val_loss: 0.0484\n",
      "Epoch 64/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 7ms/step - loss: 0.0486 - val_loss: 0.0486\n",
      "Epoch 65/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - loss: 0.0484 - val_loss: 0.0485\n",
      "Epoch 66/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - loss: 0.0485 - val_loss: 0.0481\n",
      "Epoch 67/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - loss: 0.0483 - val_loss: 0.0483\n",
      "Epoch 68/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - loss: 0.0483 - val_loss: 0.0500\n",
      "Epoch 69/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - loss: 0.0483 - val_loss: 0.0479\n",
      "Epoch 70/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - loss: 0.0482 - val_loss: 0.0484\n",
      "Epoch 71/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - loss: 0.0482 - val_loss: 0.0488\n",
      "Epoch 72/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - loss: 0.0483 - val_loss: 0.0479\n",
      "Epoch 73/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - loss: 0.0481 - val_loss: 0.0481\n",
      "Epoch 74/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - loss: 0.0482 - val_loss: 0.0481\n",
      "Epoch 75/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0479 - val_loss: 0.0477\n",
      "Epoch 76/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - loss: 0.0479 - val_loss: 0.0488\n",
      "Epoch 77/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - loss: 0.0480 - val_loss: 0.0481\n",
      "Epoch 78/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 7ms/step - loss: 0.0479 - val_loss: 0.0479\n",
      "Epoch 79/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 7ms/step - loss: 0.0479 - val_loss: 0.0480\n",
      "Epoch 80/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7ms/step - loss: 0.0479 - val_loss: 0.0478\n",
      "Epoch 81/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 7ms/step - loss: 0.0480 - val_loss: 0.0483\n",
      "Epoch 82/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7ms/step - loss: 0.0478 - val_loss: 0.0481\n",
      "Epoch 83/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 7ms/step - loss: 0.0478 - val_loss: 0.0475\n",
      "Epoch 84/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - loss: 0.0478 - val_loss: 0.0476\n",
      "Epoch 85/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - loss: 0.0478 - val_loss: 0.0478\n",
      "Epoch 86/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - loss: 0.0478 - val_loss: 0.0474\n",
      "Epoch 87/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 0.0478 - val_loss: 0.0475\n",
      "Epoch 88/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 7ms/step - loss: 0.0477 - val_loss: 0.0476\n",
      "Epoch 89/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - loss: 0.0476 - val_loss: 0.0488\n",
      "Epoch 90/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7ms/step - loss: 0.0477 - val_loss: 0.0481\n",
      "Epoch 91/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - loss: 0.0476 - val_loss: 0.0482\n",
      "Epoch 92/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - loss: 0.0476 - val_loss: 0.0479\n",
      "Epoch 93/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - loss: 0.0477 - val_loss: 0.0472\n",
      "Epoch 94/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - loss: 0.0475 - val_loss: 0.0480\n",
      "Epoch 95/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - loss: 0.0475 - val_loss: 0.0475\n",
      "Epoch 96/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 0.0476 - val_loss: 0.0469\n",
      "Epoch 97/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - loss: 0.0477 - val_loss: 0.0476\n",
      "Epoch 98/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - loss: 0.0476 - val_loss: 0.0474\n",
      "Epoch 99/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 0.0475 - val_loss: 0.0472\n",
      "Epoch 100/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - loss: 0.0474 - val_loss: 0.0474\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot serialize object <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x78595045e190> of type <class 'tensorflow.python.eager.polymorphic_function.polymorphic_function.Function'>. To be serializable, a class must implement the `get_config()` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m      8\u001b[0m dnn_ae  \u001b[38;5;241m=\u001b[39m train_dnn_ae( train, val, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mdnn_ae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/full_dnn_ae.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py:382\u001b[0m, in \u001b[0;36m_get_class_or_fn_config\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mget_registered_name(obj)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot serialize object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo be serializable, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma class must implement the `get_config()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot serialize object <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x78595045e190> of type <class 'tensorflow.python.eager.polymorphic_function.polymorphic_function.Function'>. To be serializable, a class must implement the `get_config()` method."
     ]
    }
   ],
   "source": [
    "import os \n",
    "path = '/Code/Replicate/Models'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "epochs = 100\n",
    "batch_size = 1024\n",
    "\n",
    "dnn_ae  = train_dnn_ae( train, val, epochs=epochs, batch_size=batch_size)\n",
    "# This keeps failing\n",
    "#dnn_ae.save(f'{path}/full_dnn_ae.keras')\n",
    "tmp = DNN_AE(\n",
    "        input_dim=57, latent_dim=3\n",
    "        )\n",
    "tmp.set_weights(dnn_ae.get_weights())\n",
    "tmp.save(f'{path}/full_dnn_ae.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m   6/6569\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 10ms/step - loss: 38.3073 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 09:09:28.435055: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT32 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 11ms/step - loss: 3.5095 - val_loss: 1.4083\n",
      "Epoch 2/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 11ms/step - loss: 1.3971 - val_loss: 1.3618\n",
      "Epoch 3/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 10ms/step - loss: 1.3478 - val_loss: 1.1569\n",
      "Epoch 4/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 11ms/step - loss: 1.1308 - val_loss: 1.0258\n",
      "Epoch 5/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 10ms/step - loss: 1.0170 - val_loss: 0.9727\n",
      "Epoch 6/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 10ms/step - loss: 0.9451 - val_loss: 0.8951\n",
      "Epoch 7/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 11ms/step - loss: 0.8884 - val_loss: 0.8683\n",
      "Epoch 8/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - loss: 0.8678 - val_loss: 0.8579\n",
      "Epoch 9/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 11ms/step - loss: 0.8570 - val_loss: 0.8525\n",
      "Epoch 10/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 10ms/step - loss: 0.8498 - val_loss: 0.8444\n",
      "Epoch 11/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.8445 - val_loss: 0.8414\n",
      "Epoch 12/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.8378 - val_loss: 0.8396\n",
      "Epoch 13/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - loss: 0.8322 - val_loss: 0.8324\n",
      "Epoch 14/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.8217 - val_loss: 0.7737\n",
      "Epoch 15/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - loss: 0.7624 - val_loss: 0.7447\n",
      "Epoch 16/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 10ms/step - loss: 0.7446 - val_loss: 0.7406\n",
      "Epoch 17/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 10ms/step - loss: 0.7363 - val_loss: 0.7392\n",
      "Epoch 18/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - loss: 0.7331 - val_loss: 0.7373\n",
      "Epoch 19/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.7306 - val_loss: 0.7270\n",
      "Epoch 20/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 11ms/step - loss: 0.7295 - val_loss: 0.7263\n",
      "Epoch 21/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 10ms/step - loss: 0.7265 - val_loss: 0.7332\n",
      "Epoch 22/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 10ms/step - loss: 0.7248 - val_loss: 0.7224\n",
      "Epoch 23/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 10ms/step - loss: 0.7242 - val_loss: 0.7240\n",
      "Epoch 24/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - loss: 0.7226 - val_loss: 0.7245\n",
      "Epoch 25/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - loss: 0.7218 - val_loss: 0.7243\n",
      "Epoch 26/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 11ms/step - loss: 0.7216 - val_loss: 0.7248\n",
      "Epoch 27/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 10ms/step - loss: 0.7183 - val_loss: 0.7174\n",
      "Epoch 28/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 11ms/step - loss: 0.7177 - val_loss: 0.7189\n",
      "Epoch 29/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 11ms/step - loss: 0.7181 - val_loss: 0.7198\n",
      "Epoch 30/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 11ms/step - loss: 0.7152 - val_loss: 0.7138\n",
      "Epoch 31/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 11ms/step - loss: 0.7160 - val_loss: 0.7141\n",
      "Epoch 32/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 11ms/step - loss: 0.7136 - val_loss: 0.7136\n",
      "Epoch 33/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 11ms/step - loss: 0.7129 - val_loss: 0.7167\n",
      "Epoch 34/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 11ms/step - loss: 0.7132 - val_loss: 0.7179\n",
      "Epoch 35/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - loss: 0.7109 - val_loss: 0.7167\n",
      "Epoch 36/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - loss: 0.7096 - val_loss: 0.7093\n",
      "Epoch 37/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 10ms/step - loss: 0.7086 - val_loss: 0.7070\n",
      "Epoch 38/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 10ms/step - loss: 0.7077 - val_loss: 0.7081\n",
      "Epoch 39/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 10ms/step - loss: 0.7064 - val_loss: 0.7047\n",
      "Epoch 40/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 10ms/step - loss: 0.7061 - val_loss: 0.7023\n",
      "Epoch 41/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 10ms/step - loss: 0.7030 - val_loss: 0.7072\n",
      "Epoch 42/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - loss: 0.7014 - val_loss: 0.7043\n",
      "Epoch 43/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - loss: 0.7009 - val_loss: 0.6992\n",
      "Epoch 44/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.7000 - val_loss: 0.6979\n",
      "Epoch 45/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 10ms/step - loss: 0.6986 - val_loss: 0.7013\n",
      "Epoch 46/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - loss: 0.6993 - val_loss: 0.6985\n",
      "Epoch 47/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - loss: 0.6977 - val_loss: 0.6987\n",
      "Epoch 48/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - loss: 0.6967 - val_loss: 0.6971\n",
      "Epoch 49/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 11ms/step - loss: 0.6946 - val_loss: 0.6937\n",
      "Epoch 50/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6938 - val_loss: 0.6925\n",
      "Epoch 51/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8ms/step - loss: 0.6930 - val_loss: 0.6932\n",
      "Epoch 52/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 10ms/step - loss: 0.6917 - val_loss: 0.6924\n",
      "Epoch 53/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - loss: 0.6925 - val_loss: 0.6951\n",
      "Epoch 54/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 10ms/step - loss: 0.6920 - val_loss: 0.6989\n",
      "Epoch 55/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - loss: 0.6939 - val_loss: 0.6971\n",
      "Epoch 56/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 10ms/step - loss: 0.6922 - val_loss: 0.6902\n",
      "Epoch 57/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 11ms/step - loss: 0.6910 - val_loss: 0.6920\n",
      "Epoch 58/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 10ms/step - loss: 0.6897 - val_loss: 0.6963\n",
      "Epoch 59/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 11ms/step - loss: 0.6892 - val_loss: 0.6903\n",
      "Epoch 60/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 10ms/step - loss: 0.6903 - val_loss: 0.6888\n",
      "Epoch 61/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 10ms/step - loss: 0.6898 - val_loss: 0.6920\n",
      "Epoch 62/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 10ms/step - loss: 0.6889 - val_loss: 0.6912\n",
      "Epoch 63/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 10ms/step - loss: 0.6905 - val_loss: 0.6872\n",
      "Epoch 64/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - loss: 0.6894 - val_loss: 0.6960\n",
      "Epoch 65/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - loss: 0.6886 - val_loss: 0.7083\n",
      "Epoch 66/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - loss: 0.6877 - val_loss: 0.6922\n",
      "Epoch 67/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - loss: 0.6876 - val_loss: 0.6893\n",
      "Epoch 68/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - loss: 0.6879 - val_loss: 0.6913\n",
      "Epoch 69/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 11ms/step - loss: 0.6880 - val_loss: 0.6873\n",
      "Epoch 70/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 11ms/step - loss: 0.6872 - val_loss: 0.6862\n",
      "Epoch 71/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - loss: 0.6869 - val_loss: 0.6857\n",
      "Epoch 72/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - loss: 0.6865 - val_loss: 0.6870\n",
      "Epoch 73/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - loss: 0.6874 - val_loss: 0.6871\n",
      "Epoch 74/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 10ms/step - loss: 0.6861 - val_loss: 0.6858\n",
      "Epoch 75/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.6858 - val_loss: 0.6857\n",
      "Epoch 76/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6858 - val_loss: 0.6852\n",
      "Epoch 77/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6865 - val_loss: 0.6870\n",
      "Epoch 78/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6861 - val_loss: 0.6879\n",
      "Epoch 79/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6870 - val_loss: 0.6835\n",
      "Epoch 80/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.6853 - val_loss: 0.6859\n",
      "Epoch 81/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6850 - val_loss: 0.6868\n",
      "Epoch 82/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.6840 - val_loss: 0.6904\n",
      "Epoch 83/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6849 - val_loss: 0.6879\n",
      "Epoch 84/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6848 - val_loss: 0.6918\n",
      "Epoch 85/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6845 - val_loss: 0.6909\n",
      "Epoch 86/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.6852 - val_loss: 0.6834\n",
      "Epoch 87/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6841 - val_loss: 0.7007\n",
      "Epoch 88/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.6842 - val_loss: 0.6819\n",
      "Epoch 89/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6833 - val_loss: 0.6843\n",
      "Epoch 90/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6848 - val_loss: 0.6828\n",
      "Epoch 91/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6840 - val_loss: 0.6845\n",
      "Epoch 92/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.6832 - val_loss: 0.6814\n",
      "Epoch 93/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - loss: 0.6840 - val_loss: 0.6862\n",
      "Epoch 94/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.6849 - val_loss: 0.6887\n",
      "Epoch 95/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - loss: 0.6851 - val_loss: 0.6823\n",
      "Epoch 96/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6834 - val_loss: 0.6963\n",
      "Epoch 97/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.6846 - val_loss: 0.6844\n",
      "Epoch 98/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.6824 - val_loss: 0.6825\n",
      "Epoch 99/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - loss: 0.6832 - val_loss: 0.6832\n",
      "Epoch 100/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8ms/step - loss: 0.6844 - val_loss: 0.6849\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CNN_AE.__init__() got an unexpected keyword argument 'input_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m cnn_ae  \u001b[38;5;241m=\u001b[39m train_cnn_ae( train, val, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#cnn_ae.save(f'{path}/full_cnn_ae.keras')\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mCNN_AE\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m57\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m tmp\u001b[38;5;241m.\u001b[39mset_weights(cnn_ae\u001b[38;5;241m.\u001b[39mget_weights())\n\u001b[1;32m     15\u001b[0m tmp\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/full_cnn_ae.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: CNN_AE.__init__() got an unexpected keyword argument 'input_dim'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "path = '/Code/Replicate/Models'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "epochs = 100\n",
    "batch_size = 1024\n",
    "\n",
    "cnn_ae  = train_cnn_ae( train, val, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#cnn_ae.save(f'{path}/full_cnn_ae.keras')\n",
    "tmp = CNN_AE(\n",
    "        )\n",
    "tmp.set_weights(cnn_ae.get_weights())\n",
    "tmp.save(f'{path}/full_cnn_ae.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 801.7324 - loss: 28.2326 - reconstruction_loss: 27.4586 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m  26/6569\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - kl_loss: 7.8346 - loss: 0.0820 - reconstruction_loss: 0.0742    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: kl_loss,loss,reconstruction_loss,val_kl_loss,val_reconstruction_loss,val_total_loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 7.9456 - loss: 0.0812 - reconstruction_loss: 0.0734 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 8.1541 - loss: 0.0754 - reconstruction_loss: 0.0673 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 8.2994 - loss: 0.0731 - reconstruction_loss: 0.0649 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 8.3520 - loss: 0.0714 - reconstruction_loss: 0.0631 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 8.4330 - loss: 0.0701 - reconstruction_loss: 0.0617 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 8.5598 - loss: 0.0686 - reconstruction_loss: 0.0601 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 8.6618 - loss: 0.0676 - reconstruction_loss: 0.0590 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 8.6934 - loss: 0.0668 - reconstruction_loss: 0.0582 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 8.8844 - loss: 0.0667 - reconstruction_loss: 0.0578 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 8.7956 - loss: 0.0660 - reconstruction_loss: 0.0573 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 8.7965 - loss: 0.0656 - reconstruction_loss: 0.0569 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 8.8141 - loss: 0.0653 - reconstruction_loss: 0.0566 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 8.8594 - loss: 0.0651 - reconstruction_loss: 0.0563 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 9.3441 - loss: 0.4471 - reconstruction_loss: 0.4382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 8.8712 - loss: 0.0648 - reconstruction_loss: 0.0559 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 8.8856 - loss: 0.0646 - reconstruction_loss: 0.0558 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 8.9017 - loss: 0.0644 - reconstruction_loss: 0.0556 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 8.9405 - loss: 0.0644 - reconstruction_loss: 0.0555 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 8.9235 - loss: 0.0641 - reconstruction_loss: 0.0552 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 8.9432 - loss: 0.0641 - reconstruction_loss: 0.0552 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 8.9535 - loss: 0.0638 - reconstruction_loss: 0.0549 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 8.9720 - loss: 0.0637 - reconstruction_loss: 0.0548 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 8.9969 - loss: 0.0639 - reconstruction_loss: 0.0550 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 9.0268 - loss: 0.0632 - reconstruction_loss: 0.0543 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 9.0854 - loss: 0.0631 - reconstruction_loss: 0.0540 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 9.4300 - loss: 0.7175 - reconstruction_loss: 0.7088 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 3437513.2500 - loss: 72755.6953 - reconstruction_loss: 69387.5625 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 10.4294 - loss: 0.1041 - reconstruction_loss: 0.0938 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - kl_loss: 9.1423 - loss: 0.0623 - reconstruction_loss: 0.0532 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 9.1747 - loss: 0.0622 - reconstruction_loss: 0.0531 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 9.1746 - loss: 0.0621 - reconstruction_loss: 0.0530 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 9.1866 - loss: 0.0620 - reconstruction_loss: 0.0529 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 9.2062 - loss: 0.0620 - reconstruction_loss: 0.0529 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 9.2093 - loss: 0.0618 - reconstruction_loss: 0.0527 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 9.2217 - loss: 0.0622 - reconstruction_loss: 0.0531 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 9.2314 - loss: 0.0617 - reconstruction_loss: 0.0525 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 477.6098 - loss: 7.2324 - reconstruction_loss: 6.7617 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 9.2628 - loss: 0.0617 - reconstruction_loss: 0.0525 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 9.2447 - loss: 0.0616 - reconstruction_loss: 0.0524 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 9.2459 - loss: 0.0615 - reconstruction_loss: 0.0523 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 9.2604 - loss: 0.0615 - reconstruction_loss: 0.0522 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 11.4318 - loss: 7.3928 - reconstruction_loss: 7.3887 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 9.2854 - loss: 0.0613 - reconstruction_loss: 0.0521 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 9.2662 - loss: 0.0612 - reconstruction_loss: 0.0520 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 9.2741 - loss: 0.0611 - reconstruction_loss: 0.0519 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 9.2797 - loss: 0.0612 - reconstruction_loss: 0.0520 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 9.2988 - loss: 0.0611 - reconstruction_loss: 0.0519 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 9.2850 - loss: 0.0609 - reconstruction_loss: 0.0517 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 9.2823 - loss: 0.0608 - reconstruction_loss: 0.0516 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 207.6668 - loss: 33.4355 - reconstruction_loss: 33.2612 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 9.3087 - loss: 0.0608 - reconstruction_loss: 0.0516 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 10.2570 - loss: 1.2167 - reconstruction_loss: 1.2076 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 12.5591 - loss: 3.0791 - reconstruction_loss: 3.0697 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3217 - loss: 0.0607 - reconstruction_loss: 0.0514 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - kl_loss: 102.1856 - loss: 1.2643 - reconstruction_loss: 1.1633 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 12.2729 - loss: 2.6201 - reconstruction_loss: 2.6104 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3239 - loss: 0.0605 - reconstruction_loss: 0.0513 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.3137 - loss: 0.0605 - reconstruction_loss: 0.0512 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3217 - loss: 0.0604 - reconstruction_loss: 0.0512 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 9.3255 - loss: 0.0612 - reconstruction_loss: 0.0519 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 9.3247 - loss: 0.0604 - reconstruction_loss: 0.0511 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 9.3250 - loss: 0.0603 - reconstruction_loss: 0.0510 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3404 - loss: 0.0604 - reconstruction_loss: 0.0511 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.3271 - loss: 0.0603 - reconstruction_loss: 0.0510 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 9.3353 - loss: 0.0602 - reconstruction_loss: 0.0510 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3314 - loss: 0.0603 - reconstruction_loss: 0.0510 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3499 - loss: 0.0602 - reconstruction_loss: 0.0509 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.3327 - loss: 0.0602 - reconstruction_loss: 0.0510 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 9.3323 - loss: 0.0601 - reconstruction_loss: 0.0508 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 9.3283 - loss: 0.0601 - reconstruction_loss: 0.0508 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 9.3410 - loss: 0.0601 - reconstruction_loss: 0.0508 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3335 - loss: 0.0600 - reconstruction_loss: 0.0507 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3355 - loss: 0.0600 - reconstruction_loss: 0.0507 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3314 - loss: 0.0599 - reconstruction_loss: 0.0506 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.3368 - loss: 0.0601 - reconstruction_loss: 0.0508 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 9.3515 - loss: 0.0600 - reconstruction_loss: 0.0507 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3277 - loss: 0.0600 - reconstruction_loss: 0.0507 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.3309 - loss: 0.0599 - reconstruction_loss: 0.0506 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3340 - loss: 0.0599 - reconstruction_loss: 0.0507 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.3370 - loss: 0.0599 - reconstruction_loss: 0.0506 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3326 - loss: 0.0599 - reconstruction_loss: 0.0506 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3218 - loss: 0.0598 - reconstruction_loss: 0.0506 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3529 - loss: 0.0599 - reconstruction_loss: 0.0506 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 11.2225 - loss: 0.1404 - reconstruction_loss: 0.1293 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 51666728.0000 - loss: 89830.8047 - reconstruction_loss: 38202.2773 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 9.3585 - loss: 0.0600 - reconstruction_loss: 0.0507 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 9.3399 - loss: 0.0598 - reconstruction_loss: 0.0505 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.3408 - loss: 0.0598 - reconstruction_loss: 0.0505 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 13.8396 - loss: 0.2722 - reconstruction_loss: 0.2586 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.3385 - loss: 0.0598 - reconstruction_loss: 0.0505 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.3771 - loss: 0.0599 - reconstruction_loss: 0.0506 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 9.3417 - loss: 0.0598 - reconstruction_loss: 0.0505 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 9.3420 - loss: 0.0602 - reconstruction_loss: 0.0509 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - kl_loss: 9.3642 - loss: 0.0657 - reconstruction_loss: 0.0564 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 2042.0330 - loss: 3826.6963 - reconstruction_loss: 3828.4827 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 10178.4053 - loss: 4885.6919 - reconstruction_loss: 4880.3936 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 205.4945 - loss: 82.6251 - reconstruction_loss: 82.5057 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 11.3254 - loss: 0.3038 - reconstruction_loss: 0.2928 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - kl_loss: 87.3880 - loss: 2.5521 - reconstruction_loss: 2.4672 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py:107: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
      "  return saving_lib.save_model(model, filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - kl_loss: 4.4773 - loss: 0.2304 - reconstruction_loss: 0.1875 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 3.7308 - loss: 0.1278 - reconstruction_loss: 0.0914 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 3.9671 - loss: 0.1235 - reconstruction_loss: 0.0847 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.0934 - loss: 0.1210 - reconstruction_loss: 0.0809 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 4.1181 - loss: 0.1203 - reconstruction_loss: 0.0800 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.1328 - loss: 0.1198 - reconstruction_loss: 0.0793 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.1471 - loss: 0.1195 - reconstruction_loss: 0.0788 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.1609 - loss: 0.1191 - reconstruction_loss: 0.0783 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.1835 - loss: 0.1196 - reconstruction_loss: 0.0785 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.1890 - loss: 0.1186 - reconstruction_loss: 0.0775 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.2072 - loss: 0.1184 - reconstruction_loss: 0.0771 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.4444 - loss: 0.1343 - reconstruction_loss: 0.0907 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.2515 - loss: 0.1179 - reconstruction_loss: 0.0761 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.2839 - loss: 0.1176 - reconstruction_loss: 0.0755 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 82.1616 - loss: 3.1663 - reconstruction_loss: 2.3684 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.3495 - loss: 0.1171 - reconstruction_loss: 0.0744 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.3682 - loss: 0.1168 - reconstruction_loss: 0.0738 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.3835 - loss: 0.1167 - reconstruction_loss: 0.0736 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.3968 - loss: 0.1165 - reconstruction_loss: 0.0733 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 9.9301 - loss: 10.5226 - reconstruction_loss: 10.5284 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.4390 - loss: 0.1396 - reconstruction_loss: 0.0962 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.4276 - loss: 0.1160 - reconstruction_loss: 0.0725 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.4691 - loss: 0.1270 - reconstruction_loss: 0.0831 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 14.8386 - loss: 33.7042 - reconstruction_loss: 33.8939 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.4640 - loss: 0.1159 - reconstruction_loss: 0.0719 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6353 - loss: 0.5123 - reconstruction_loss: 0.4706 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.4661 - loss: 0.1173 - reconstruction_loss: 0.0733 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 5.0707 - loss: 0.1217 - reconstruction_loss: 0.0717 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.4778 - loss: 0.1155 - reconstruction_loss: 0.0714 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 5.1354 - loss: 0.1226 - reconstruction_loss: 0.0720 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.4917 - loss: 0.1154 - reconstruction_loss: 0.0712 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.5152 - loss: 0.1437 - reconstruction_loss: 0.0996 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.5049 - loss: 0.1152 - reconstruction_loss: 0.0709 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.5504 - loss: 0.3598 - reconstruction_loss: 0.3175 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.5316 - loss: 0.1203 - reconstruction_loss: 0.0758 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.5241 - loss: 0.1150 - reconstruction_loss: 0.0705 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.9461 - loss: 0.1203 - reconstruction_loss: 0.0716 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.5261 - loss: 0.1148 - reconstruction_loss: 0.0702 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.5286 - loss: 0.1148 - reconstruction_loss: 0.0702 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.5359 - loss: 0.1148 - reconstruction_loss: 0.0701 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.5376 - loss: 0.1146 - reconstruction_loss: 0.0700 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 4.5517 - loss: 0.1344 - reconstruction_loss: 0.0898 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.5448 - loss: 0.1146 - reconstruction_loss: 0.0699 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.5559 - loss: 0.1147 - reconstruction_loss: 0.0698 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 148.4785 - loss: 12.7849 - reconstruction_loss: 11.4142 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 4.5747 - loss: 0.1243 - reconstruction_loss: 0.0794 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.5625 - loss: 0.1377 - reconstruction_loss: 0.0930 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.5631 - loss: 0.1146 - reconstruction_loss: 0.0696 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.5726 - loss: 0.1147 - reconstruction_loss: 0.0697 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 4.5665 - loss: 0.1145 - reconstruction_loss: 0.0695 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 16.0117 - loss: 80.7686 - reconstruction_loss: 81.4241 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.5848 - loss: 0.1283 - reconstruction_loss: 0.0833 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 4.5719 - loss: 0.1143 - reconstruction_loss: 0.0693 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 4.5793 - loss: 0.1144 - reconstruction_loss: 0.0693 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.5777 - loss: 0.1143 - reconstruction_loss: 0.0692 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.5819 - loss: 0.1142 - reconstruction_loss: 0.0691 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.5884 - loss: 0.1145 - reconstruction_loss: 0.0693 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.5864 - loss: 0.1142 - reconstruction_loss: 0.0690 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.5859 - loss: 0.1142 - reconstruction_loss: 0.0690 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.7823 - loss: 2.6924 - reconstruction_loss: 2.6713 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.5887 - loss: 0.1141 - reconstruction_loss: 0.0689 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.5983 - loss: 0.1144 - reconstruction_loss: 0.0691 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.5942 - loss: 0.1141 - reconstruction_loss: 0.0689 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 4.5936 - loss: 0.1141 - reconstruction_loss: 0.0689 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.5946 - loss: 0.1140 - reconstruction_loss: 0.0688 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.5955 - loss: 0.1140 - reconstruction_loss: 0.0687 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 4.6005 - loss: 0.1140 - reconstruction_loss: 0.0687 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.6080 - loss: 0.1141 - reconstruction_loss: 0.0687 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6069 - loss: 0.1141 - reconstruction_loss: 0.0687 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6043 - loss: 0.1139 - reconstruction_loss: 0.0686 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6041 - loss: 0.1139 - reconstruction_loss: 0.0685 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6030 - loss: 0.1139 - reconstruction_loss: 0.0685 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6065 - loss: 0.1144 - reconstruction_loss: 0.0690 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 4.6028 - loss: 0.1139 - reconstruction_loss: 0.0685 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6048 - loss: 0.1139 - reconstruction_loss: 0.0685 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.6126 - loss: 0.1139 - reconstruction_loss: 0.0685 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6083 - loss: 0.1139 - reconstruction_loss: 0.0686 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6067 - loss: 0.1138 - reconstruction_loss: 0.0684 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6091 - loss: 0.1138 - reconstruction_loss: 0.0684 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6186 - loss: 0.1140 - reconstruction_loss: 0.0685 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6110 - loss: 0.1138 - reconstruction_loss: 0.0683 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.6163 - loss: 0.1139 - reconstruction_loss: 0.0685 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 4.6115 - loss: 0.1137 - reconstruction_loss: 0.0683 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6205 - loss: 0.1139 - reconstruction_loss: 0.0683 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.6142 - loss: 0.1137 - reconstruction_loss: 0.0682 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6111 - loss: 0.1137 - reconstruction_loss: 0.0682 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6125 - loss: 0.1136 - reconstruction_loss: 0.0682 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 4.6142 - loss: 0.1137 - reconstruction_loss: 0.0683 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 4.6168 - loss: 0.1136 - reconstruction_loss: 0.0681 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 4.6141 - loss: 0.1135 - reconstruction_loss: 0.0681 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6145 - loss: 0.1137 - reconstruction_loss: 0.0682 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6190 - loss: 0.1136 - reconstruction_loss: 0.0681 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6192 - loss: 0.1135 - reconstruction_loss: 0.0680 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6168 - loss: 0.1136 - reconstruction_loss: 0.0681 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 4.6204 - loss: 0.1135 - reconstruction_loss: 0.0680 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 4.6213 - loss: 0.1137 - reconstruction_loss: 0.0682 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6194 - loss: 0.1136 - reconstruction_loss: 0.0681 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.6211 - loss: 0.1136 - reconstruction_loss: 0.0680 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 4.6189 - loss: 0.1135 - reconstruction_loss: 0.0680 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.6244 - loss: 0.1135 - reconstruction_loss: 0.0680 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 1/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 8ms/step - kl_loss: 0.5142 - loss: 0.3263 - reconstruction_loss: 0.3054 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4890 - loss: 0.2525 - reconstruction_loss: 0.2262 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4815 - loss: 0.2516 - reconstruction_loss: 0.2261 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4847 - loss: 0.2506 - reconstruction_loss: 0.2246 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4888 - loss: 0.2503 - reconstruction_loss: 0.2238 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4894 - loss: 0.2494 - reconstruction_loss: 0.2227 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - kl_loss: 0.4916 - loss: 0.2494 - reconstruction_loss: 0.2225 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4923 - loss: 0.2492 - reconstruction_loss: 0.2222 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4918 - loss: 0.2491 - reconstruction_loss: 0.2221 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4937 - loss: 0.2495 - reconstruction_loss: 0.2224 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4943 - loss: 0.2492 - reconstruction_loss: 0.2220 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4941 - loss: 0.2488 - reconstruction_loss: 0.2216 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4949 - loss: 0.2491 - reconstruction_loss: 0.2218 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 0.4959 - loss: 0.2488 - reconstruction_loss: 0.2213 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4950 - loss: 0.2486 - reconstruction_loss: 0.2212 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4957 - loss: 0.2489 - reconstruction_loss: 0.2215 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4955 - loss: 0.2486 - reconstruction_loss: 0.2212 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4949 - loss: 0.2486 - reconstruction_loss: 0.2212 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4962 - loss: 0.2487 - reconstruction_loss: 0.2212 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4961 - loss: 0.2486 - reconstruction_loss: 0.2211 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4961 - loss: 0.2487 - reconstruction_loss: 0.2212 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4966 - loss: 0.2487 - reconstruction_loss: 0.2211 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4948 - loss: 0.2485 - reconstruction_loss: 0.2212 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4960 - loss: 0.2486 - reconstruction_loss: 0.2211 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4960 - loss: 0.2484 - reconstruction_loss: 0.2209 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4962 - loss: 0.2486 - reconstruction_loss: 0.2211 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4946 - loss: 0.2483 - reconstruction_loss: 0.2210 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4962 - loss: 0.2486 - reconstruction_loss: 0.2210 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4972 - loss: 0.2485 - reconstruction_loss: 0.2209 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4959 - loss: 0.2486 - reconstruction_loss: 0.2211 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4955 - loss: 0.2484 - reconstruction_loss: 0.2209 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4964 - loss: 0.2485 - reconstruction_loss: 0.2209 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4967 - loss: 0.2482 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4967 - loss: 0.2484 - reconstruction_loss: 0.2209 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4964 - loss: 0.2483 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4966 - loss: 0.2484 - reconstruction_loss: 0.2209 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4965 - loss: 0.2484 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4970 - loss: 0.2484 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4974 - loss: 0.2485 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4970 - loss: 0.2484 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4975 - loss: 0.2485 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4969 - loss: 0.2483 - reconstruction_loss: 0.2207 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4978 - loss: 0.2485 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4962 - loss: 0.2483 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4961 - loss: 0.2483 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4974 - loss: 0.2483 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 0.4971 - loss: 0.2485 - reconstruction_loss: 0.2209 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4972 - loss: 0.2486 - reconstruction_loss: 0.2210 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4966 - loss: 0.2481 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 96431560.0000 - loss: 25072112.0000 - reconstruction_loss: 17143284.0000 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4987 - loss: 0.2486 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4964 - loss: 0.2484 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 0.4978 - loss: 0.2483 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - kl_loss: 0.4971 - loss: 0.2484 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4976 - loss: 0.2483 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4967 - loss: 0.2482 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4992 - loss: 0.2486 - reconstruction_loss: 0.2207 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4970 - loss: 0.2483 - reconstruction_loss: 0.2207 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 363938.4062 - loss: 91985.4375 - reconstruction_loss: 61768.4414 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4969 - loss: 0.2482 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4990 - loss: 0.2485 - reconstruction_loss: 0.2207 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 0.4977 - loss: 0.2484 - reconstruction_loss: 0.2207 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4978 - loss: 0.2485 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4989 - loss: 0.2486 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4966 - loss: 0.2482 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4984 - loss: 0.2483 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4974 - loss: 0.2483 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4981 - loss: 0.2484 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4981 - loss: 0.2486 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4969 - loss: 0.2483 - reconstruction_loss: 0.2207 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4972 - loss: 0.2482 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4978 - loss: 0.2482 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4979 - loss: 0.2483 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4977 - loss: 0.2484 - reconstruction_loss: 0.2207 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4970 - loss: 0.2481 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.5196 - loss: 0.2505 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4987 - loss: 0.2484 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4985 - loss: 0.2484 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4993 - loss: 0.2488 - reconstruction_loss: 0.2209 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4973 - loss: 0.2482 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4970 - loss: 0.2482 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4980 - loss: 0.2484 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4987 - loss: 0.2482 - reconstruction_loss: 0.2203 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4986 - loss: 0.2484 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4995 - loss: 0.2485 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4977 - loss: 0.2485 - reconstruction_loss: 0.2208 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4981 - loss: 0.2482 - reconstruction_loss: 0.2204 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4980 - loss: 0.2486 - reconstruction_loss: 0.2209 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4979 - loss: 0.2484 - reconstruction_loss: 0.2207 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4973 - loss: 0.2481 - reconstruction_loss: 0.2204 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4973 - loss: 0.2483 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 0.4982 - loss: 0.2484 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4968 - loss: 0.2481 - reconstruction_loss: 0.2204 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.4978 - loss: 0.2483 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4980 - loss: 0.2483 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4980 - loss: 0.2484 - reconstruction_loss: 0.2207 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 0.4973 - loss: 0.2482 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4978 - loss: 0.2481 - reconstruction_loss: 0.2204 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - kl_loss: 0.4989 - loss: 0.2484 - reconstruction_loss: 0.2206 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 0.4978 - loss: 0.2482 - reconstruction_loss: 0.2205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 1/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - kl_loss: 0.0121 - loss: 0.0121 - reconstruction_loss: 2.0380 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 8.4862e-06 - loss: 8.4862e-06 - reconstruction_loss: 2.0388 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 1.9226e-06 - loss: 1.9226e-06 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 2.2025e-06 - loss: 2.2025e-06 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 1.2915e-06 - loss: 1.2915e-06 - reconstruction_loss: 2.0387 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 3.2291e-07 - loss: 3.2291e-07 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 2.2269e-07 - loss: 2.2269e-07 - reconstruction_loss: 2.0375 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 7.4964e-07 - loss: 7.4964e-07 - reconstruction_loss: 2.0383 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.8443e-07 - loss: 1.8443e-07 - reconstruction_loss: 2.0375 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.4467e-07 - loss: 1.4467e-07 - reconstruction_loss: 2.0384 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 1.0616e-07 - loss: 1.0616e-07 - reconstruction_loss: 2.0383 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 6.9182e-07 - loss: 6.9182e-07 - reconstruction_loss: 2.0375 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 6.6276e-08 - loss: 6.6276e-08 - reconstruction_loss: 2.0373 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 2.2867e-07 - loss: 2.2867e-07 - reconstruction_loss: 2.0385 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 8.7247e-08 - loss: 8.7247e-08 - reconstruction_loss: 2.0396 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.8275e-08 - loss: 4.8275e-08 - reconstruction_loss: 2.0374 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.8246e-08 - loss: 1.8246e-08 - reconstruction_loss: 2.0375 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 1.6503e-08 - loss: 1.6503e-08 - reconstruction_loss: 2.0382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 4.9962e-08 - loss: 4.9962e-08 - reconstruction_loss: 2.0387 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 1.8428e-08 - loss: 1.8428e-08 - reconstruction_loss: 2.0379 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 1.0080e-07 - loss: 1.0080e-07 - reconstruction_loss: 2.0382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.8671e-08 - loss: 1.8671e-08 - reconstruction_loss: 2.0376 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.4649e-08 - loss: 1.4649e-08 - reconstruction_loss: 2.0391 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 3.4253e-08 - loss: 3.4253e-08 - reconstruction_loss: 2.0392 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 2.7754e-08 - loss: 2.7754e-08 - reconstruction_loss: 2.0395 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 3.3108e-09 - loss: 3.3108e-09 - reconstruction_loss: 2.0382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 1.8870e-09 - loss: 1.8870e-09 - reconstruction_loss: 2.0380 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 8.6241e-09 - loss: 8.6241e-09 - reconstruction_loss: 2.0380 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 2.6809e-08 - loss: 2.6809e-08 - reconstruction_loss: 2.0375 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 7.8652e-08 - loss: 7.8652e-08 - reconstruction_loss: 2.0377 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.2968e-08 - loss: 1.2968e-08 - reconstruction_loss: 2.0386 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.1915e-08 - loss: 9.1915e-08 - reconstruction_loss: 2.0376 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 1.1145e-08 - loss: 1.1145e-08 - reconstruction_loss: 2.0379 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 3.3997e-08 - loss: 3.3997e-08 - reconstruction_loss: 2.0395 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 2.0132e-08 - loss: 2.0132e-08 - reconstruction_loss: 2.0383 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 5.4855e-09 - loss: 5.4855e-09 - reconstruction_loss: 2.0382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 8.6480e-09 - loss: 8.6480e-09 - reconstruction_loss: 2.0382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 6.8797e-09 - loss: 6.8797e-09 - reconstruction_loss: 2.0391 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 4.8302e-08 - loss: 4.8302e-08 - reconstruction_loss: 2.0383 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.0445e-09 - loss: 4.0445e-09 - reconstruction_loss: 2.0382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.6912e-09 - loss: 1.6912e-09 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 3.4540e-08 - loss: 3.4540e-08 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 3.5089e-09 - loss: 3.5089e-09 - reconstruction_loss: 2.0370 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 2.6947e-09 - loss: 2.6947e-09 - reconstruction_loss: 2.0374 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.6492e-09 - loss: 1.6492e-09 - reconstruction_loss: 2.0377 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 2.6363e-08 - loss: 2.6363e-08 - reconstruction_loss: 2.0377 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.5668e-09 - loss: 1.5668e-09 - reconstruction_loss: 2.0381 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.2662e-09 - loss: 1.2662e-09 - reconstruction_loss: 2.0374 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 1.0687e-09 - loss: 1.0687e-09 - reconstruction_loss: 2.0390 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 7.5836e-10 - loss: 7.5836e-10 - reconstruction_loss: 2.0382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.1850e-08 - loss: 4.1850e-08 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 4.6177e-09 - loss: 4.6177e-09 - reconstruction_loss: 2.0384 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 9.7635e-10 - loss: 9.7635e-10 - reconstruction_loss: 2.0367 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 4.6451e-10 - loss: 4.6451e-10 - reconstruction_loss: 2.0379 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 9.2226e-10 - loss: 9.2226e-10 - reconstruction_loss: 2.0389 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 5.2324e-10 - loss: 5.2324e-10 - reconstruction_loss: 2.0377 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 1.8928e-10 - loss: 1.8928e-10 - reconstruction_loss: 2.0377 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 1.0342e-07 - loss: 1.0342e-07 - reconstruction_loss: 2.0377 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 1.5751e-09 - loss: 1.5751e-09 - reconstruction_loss: 2.0389 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 1.8425e-09 - loss: 1.8425e-09 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 8.1627e-11 - loss: 8.1627e-11 - reconstruction_loss: 2.0376 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 5.5273e-11 - loss: 5.5273e-11 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 7.2208e-12 - loss: 7.2208e-12 - reconstruction_loss: 2.0381 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 3.5184e-11 - loss: 3.5184e-11 - reconstruction_loss: 2.0387 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 2.7625e-11 - loss: 2.7625e-11 - reconstruction_loss: 2.0387 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - kl_loss: 1.6425e-10 - loss: 1.6425e-10 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 7.0681e-11 - loss: 7.0681e-11 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 3.8348e-08 - loss: 3.8348e-08 - reconstruction_loss: 2.0375 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 2.7487e-09 - loss: 2.7487e-09 - reconstruction_loss: 2.0388 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 1.0401e-10 - loss: 1.0401e-10 - reconstruction_loss: 2.0386 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 2.1759e-11 - loss: 2.1759e-11 - reconstruction_loss: 2.0388 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.3097e-11 - loss: 1.3097e-11 - reconstruction_loss: 2.0374 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 2.4919e-12 - loss: 2.4919e-12 - reconstruction_loss: 2.0386 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 8.2082e-12 - loss: 8.2082e-12 - reconstruction_loss: 2.0393 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 1.3301e-12 - loss: 1.3301e-12 - reconstruction_loss: 2.0377 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 9.9957e-12 - loss: 9.9957e-12 - reconstruction_loss: 2.0374 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 2.1629e-12 - loss: 2.1629e-12 - reconstruction_loss: 2.0376 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 1.0631e-11 - loss: 1.0631e-11 - reconstruction_loss: 2.0382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - kl_loss: 5.6249e-13 - loss: 5.6249e-13 - reconstruction_loss: 2.0376 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 3.1830e-10 - loss: 3.1830e-10 - reconstruction_loss: 2.0399 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 9.5792e-13 - loss: 9.5792e-13 - reconstruction_loss: 2.0381 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 8.7986e-13 - loss: 8.7986e-13 - reconstruction_loss: 2.0387 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 3.0809e-13 - loss: 3.0809e-13 - reconstruction_loss: 2.0379 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 3.0969e-13 - loss: 3.0969e-13 - reconstruction_loss: 2.0377 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 1.1584e-13 - loss: 1.1584e-13 - reconstruction_loss: 2.0372 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 8.1940e-12 - loss: 8.1940e-12 - reconstruction_loss: 2.0376 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.1159e-14 - loss: 4.1159e-14 - reconstruction_loss: 2.0379 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 1.9482e-14 - loss: 1.9482e-14 - reconstruction_loss: 2.0376 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 0.0000e+00 - loss: 0.0000e+00 - reconstruction_loss: 2.0384 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 1.4827e-14 - loss: 1.4827e-14 - reconstruction_loss: 2.0379 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 2.7048e-12 - loss: 2.7048e-12 - reconstruction_loss: 2.0394 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 7.6657e-16 - loss: 7.6657e-16 - reconstruction_loss: 2.0372 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 8.0989e-12 - loss: 8.0989e-12 - reconstruction_loss: 2.0378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - kl_loss: 1.1128e-13 - loss: 1.1128e-13 - reconstruction_loss: 2.0382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 1.8879e-11 - loss: 1.8879e-11 - reconstruction_loss: 2.0373 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 4.9701e-12 - loss: 4.9701e-12 - reconstruction_loss: 2.0385 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - kl_loss: 1.8878e-12 - loss: 1.8878e-12 - reconstruction_loss: 2.0379 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - kl_loss: 1.7463e-11 - loss: 1.7463e-11 - reconstruction_loss: 2.0382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - kl_loss: 4.7765e-14 - loss: 4.7765e-14 - reconstruction_loss: 2.0386 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - kl_loss: 4.4501e-13 - loss: 4.4501e-13 - reconstruction_loss: 2.0381 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# Iterate e-3 to e0 \n",
    "for i in np.logspace(-3, 0, 4):\n",
    "    path = '/Code/Replicate/Models'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    epochs = 100\n",
    "    batch_size = 1024\n",
    "\n",
    "    dnn_vae = train_dnn_vae(train, val, epochs=epochs, batch_size=batch_size, beta=i)\n",
    "\n",
    "    #dnn_vae.save(f'{path}/full_dnn_vae_beta{i}.keras')\n",
    "    tmp = DNN_VAE(eta_b=eta_b, phi_b=phi_b, input_dim=57, latent_dim=3, beta=i\n",
    "            )\n",
    "    tmp.set_weights(dnn_vae.get_weights())\n",
    "    tmp.save(f'{path}/full_dnn_vae_beta{i}.keras')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 12ms/step - kl_loss: 40.0657 - loss: 3.5691 - reconstruction_loss: 3.5325 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m  11/6569\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - kl_loss: 33.2840 - loss: 1.4031 - reconstruction_loss: 1.3712    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: kl_loss,loss,reconstruction_loss,val_kl_loss,val_reconstruction_loss,val_total_loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 32.8342 - loss: 1.3798 - reconstruction_loss: 1.3483 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 30.6684 - loss: 1.3562 - reconstruction_loss: 1.3268 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 29.0733 - loss: 1.3378 - reconstruction_loss: 1.3100 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 30.9631 - loss: 0.9796 - reconstruction_loss: 0.9496 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 31.1319 - loss: 0.8620 - reconstruction_loss: 0.8317 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 31.0585 - loss: 0.7970 - reconstruction_loss: 0.7667 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 30.9274 - loss: 0.7671 - reconstruction_loss: 0.7369 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 30.8110 - loss: 0.7598 - reconstruction_loss: 0.7298 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 30.6871 - loss: 0.7543 - reconstruction_loss: 0.7243 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 30.5750 - loss: 0.7519 - reconstruction_loss: 0.7221 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 30.4674 - loss: 0.7476 - reconstruction_loss: 0.7178 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 30.2815 - loss: 0.7463 - reconstruction_loss: 0.7167 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 30.1144 - loss: 0.7438 - reconstruction_loss: 0.7144 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 29.9754 - loss: 0.7417 - reconstruction_loss: 0.7124 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 29.8805 - loss: 0.7406 - reconstruction_loss: 0.7114 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 29.6047 - loss: 0.7392 - reconstruction_loss: 0.7103 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 29.4592 - loss: 0.7382 - reconstruction_loss: 0.7094 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 29.3658 - loss: 0.7368 - reconstruction_loss: 0.7082 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 29.4105 - loss: 0.7348 - reconstruction_loss: 0.7061 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 29.2104 - loss: 0.7349 - reconstruction_loss: 0.7064 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 29.1044 - loss: 0.7336 - reconstruction_loss: 0.7052 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 29.0933 - loss: 0.7320 - reconstruction_loss: 0.7036 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 28.9607 - loss: 0.7301 - reconstruction_loss: 0.7019 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 28.8618 - loss: 0.7300 - reconstruction_loss: 0.7018 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 28.8392 - loss: 0.7286 - reconstruction_loss: 0.7004 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 28.5830 - loss: 0.7276 - reconstruction_loss: 0.6997 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 28.5507 - loss: 0.7279 - reconstruction_loss: 0.7000 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 31.7092 - loss: 0.7311 - reconstruction_loss: 0.7001 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 28.6456 - loss: 0.7257 - reconstruction_loss: 0.6977 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 28.3022 - loss: 0.7257 - reconstruction_loss: 0.6981 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 28.2084 - loss: 0.7241 - reconstruction_loss: 0.6966 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 28.1222 - loss: 0.7234 - reconstruction_loss: 0.6959 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 28.0790 - loss: 0.7232 - reconstruction_loss: 0.6958 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 27.9620 - loss: 0.7219 - reconstruction_loss: 0.6946 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.8866 - loss: 0.7219 - reconstruction_loss: 0.6947 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 27.8535 - loss: 0.7204 - reconstruction_loss: 0.6933 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.7923 - loss: 0.7207 - reconstruction_loss: 0.6936 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.7548 - loss: 0.7192 - reconstruction_loss: 0.6922 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 27.7185 - loss: 0.7191 - reconstruction_loss: 0.6920 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.6693 - loss: 0.7188 - reconstruction_loss: 0.6918 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 27.7082 - loss: 0.7174 - reconstruction_loss: 0.6904 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 27.6543 - loss: 0.7167 - reconstruction_loss: 0.6898 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.5666 - loss: 0.7164 - reconstruction_loss: 0.6895 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.5465 - loss: 0.7151 - reconstruction_loss: 0.6882 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.4404 - loss: 0.7143 - reconstruction_loss: 0.6875 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 27.3891 - loss: 0.7129 - reconstruction_loss: 0.6862 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.3426 - loss: 0.7139 - reconstruction_loss: 0.6872 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.3069 - loss: 0.7130 - reconstruction_loss: 0.6864 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 27.5722 - loss: 0.7118 - reconstruction_loss: 0.6849 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.2345 - loss: 0.7111 - reconstruction_loss: 0.6845 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 27.3027 - loss: 0.7104 - reconstruction_loss: 0.6838 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.1809 - loss: 0.7099 - reconstruction_loss: 0.6834 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.3683 - loss: 0.7103 - reconstruction_loss: 0.6837 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.1686 - loss: 0.7101 - reconstruction_loss: 0.6836 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.2025 - loss: 0.7094 - reconstruction_loss: 0.6829 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 27.1173 - loss: 0.7087 - reconstruction_loss: 0.6822 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 27.1132 - loss: 0.7091 - reconstruction_loss: 0.6826 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 27.0980 - loss: 0.7074 - reconstruction_loss: 0.6810 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 27.0934 - loss: 0.7092 - reconstruction_loss: 0.6828 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 27.0884 - loss: 0.7083 - reconstruction_loss: 0.6819 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 27.0356 - loss: 0.7069 - reconstruction_loss: 0.6805 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 27.0064 - loss: 0.7064 - reconstruction_loss: 0.6801 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 26.9758 - loss: 0.7059 - reconstruction_loss: 0.6796 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.9926 - loss: 0.7064 - reconstruction_loss: 0.6801 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.8916 - loss: 0.7059 - reconstruction_loss: 0.6797 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 26.8559 - loss: 0.7053 - reconstruction_loss: 0.6791 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 26.8267 - loss: 0.7049 - reconstruction_loss: 0.6788 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 26.7932 - loss: 0.7055 - reconstruction_loss: 0.6794 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.7438 - loss: 0.7035 - reconstruction_loss: 0.6774 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 26.7715 - loss: 0.7046 - reconstruction_loss: 0.6785 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.6952 - loss: 0.7038 - reconstruction_loss: 0.6778 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.6551 - loss: 0.7025 - reconstruction_loss: 0.6765 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.6580 - loss: 0.7032 - reconstruction_loss: 0.6772 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.6189 - loss: 0.7031 - reconstruction_loss: 0.6771 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 26.5319 - loss: 0.7034 - reconstruction_loss: 0.6775 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.5201 - loss: 0.7029 - reconstruction_loss: 0.6770 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 26.5113 - loss: 0.7024 - reconstruction_loss: 0.6766 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 26.4495 - loss: 0.7038 - reconstruction_loss: 0.6781 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 27.0150 - loss: 0.7053 - reconstruction_loss: 0.6789 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.5596 - loss: 0.7020 - reconstruction_loss: 0.6761 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 26.3695 - loss: 0.7022 - reconstruction_loss: 0.6765 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.3394 - loss: 0.7018 - reconstruction_loss: 0.6761 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 26.3127 - loss: 0.7012 - reconstruction_loss: 0.6755 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.3409 - loss: 0.7020 - reconstruction_loss: 0.6763 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 26.2381 - loss: 0.7004 - reconstruction_loss: 0.6748 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 26.2179 - loss: 0.7024 - reconstruction_loss: 0.6769 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.1770 - loss: 0.7003 - reconstruction_loss: 0.6747 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 26.1843 - loss: 0.7008 - reconstruction_loss: 0.6753 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.1526 - loss: 0.7020 - reconstruction_loss: 0.6765 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.1059 - loss: 0.7009 - reconstruction_loss: 0.6755 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 26.1048 - loss: 0.7016 - reconstruction_loss: 0.6762 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.0859 - loss: 0.7014 - reconstruction_loss: 0.6760 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 26.0653 - loss: 0.6992 - reconstruction_loss: 0.6739 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 26.0376 - loss: 0.7008 - reconstruction_loss: 0.6754 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 26.0250 - loss: 0.7004 - reconstruction_loss: 0.6751 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 26.0145 - loss: 0.7004 - reconstruction_loss: 0.6750 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 25.9826 - loss: 0.6993 - reconstruction_loss: 0.6740 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 25.9626 - loss: 0.6990 - reconstruction_loss: 0.6737 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 25.9727 - loss: 0.6995 - reconstruction_loss: 0.6742 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py:107: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
      "  return saving_lib.save_model(model, filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 10ms/step - kl_loss: 16.4385 - loss: 3.5213 - reconstruction_loss: 3.3908 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 12.5173 - loss: 1.4854 - reconstruction_loss: 1.3739 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.2082 - loss: 1.1972 - reconstruction_loss: 1.0658 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 15.7020 - loss: 0.9583 - reconstruction_loss: 0.8094 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 15.6890 - loss: 0.9250 - reconstruction_loss: 0.7759 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 15.5279 - loss: 0.9125 - reconstruction_loss: 0.7649 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 15.3952 - loss: 0.9070 - reconstruction_loss: 0.7606 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 15.2823 - loss: 0.9012 - reconstruction_loss: 0.7559 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 15.2002 - loss: 0.8974 - reconstruction_loss: 0.7530 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 15.1478 - loss: 0.8948 - reconstruction_loss: 0.7509 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - kl_loss: 15.1156 - loss: 0.8908 - reconstruction_loss: 0.7471 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 15.0742 - loss: 0.8895 - reconstruction_loss: 0.7463 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 15.0678 - loss: 0.8881 - reconstruction_loss: 0.7448 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 15.0112 - loss: 0.8847 - reconstruction_loss: 0.7420 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 14.9987 - loss: 0.8847 - reconstruction_loss: 0.7421 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9897 - loss: 0.8848 - reconstruction_loss: 0.7423 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9740 - loss: 0.8829 - reconstruction_loss: 0.7406 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9552 - loss: 0.8810 - reconstruction_loss: 0.7389 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9910 - loss: 0.8814 - reconstruction_loss: 0.7388 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 14.9439 - loss: 0.8793 - reconstruction_loss: 0.7372 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9481 - loss: 0.8779 - reconstruction_loss: 0.7358 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9429 - loss: 0.8769 - reconstruction_loss: 0.7348 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9362 - loss: 0.8754 - reconstruction_loss: 0.7334 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9276 - loss: 0.8726 - reconstruction_loss: 0.7306 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9329 - loss: 0.8733 - reconstruction_loss: 0.7313 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9319 - loss: 0.8725 - reconstruction_loss: 0.7305 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9222 - loss: 0.8700 - reconstruction_loss: 0.7281 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9215 - loss: 0.8698 - reconstruction_loss: 0.7279 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9228 - loss: 0.8693 - reconstruction_loss: 0.7273 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9219 - loss: 0.8679 - reconstruction_loss: 0.7260 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9175 - loss: 0.8672 - reconstruction_loss: 0.7253 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9188 - loss: 0.8667 - reconstruction_loss: 0.7247 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9207 - loss: 0.8669 - reconstruction_loss: 0.7249 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 14.9175 - loss: 0.8666 - reconstruction_loss: 0.7247 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9248 - loss: 0.8660 - reconstruction_loss: 0.7240 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9153 - loss: 0.8643 - reconstruction_loss: 0.7223 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9284 - loss: 0.8641 - reconstruction_loss: 0.7220 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9352 - loss: 0.8633 - reconstruction_loss: 0.7211 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9412 - loss: 0.8626 - reconstruction_loss: 0.7203 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9632 - loss: 0.8609 - reconstruction_loss: 0.7185 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9736 - loss: 0.8608 - reconstruction_loss: 0.7182 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9712 - loss: 0.8592 - reconstruction_loss: 0.7167 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9764 - loss: 0.8591 - reconstruction_loss: 0.7165 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9798 - loss: 0.8586 - reconstruction_loss: 0.7159 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9792 - loss: 0.8580 - reconstruction_loss: 0.7154 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 15.0093 - loss: 0.8577 - reconstruction_loss: 0.7147 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9657 - loss: 0.8569 - reconstruction_loss: 0.7143 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9710 - loss: 0.8564 - reconstruction_loss: 0.7139 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9589 - loss: 0.8549 - reconstruction_loss: 0.7124 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9677 - loss: 0.8564 - reconstruction_loss: 0.7139 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9678 - loss: 0.8542 - reconstruction_loss: 0.7116 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9628 - loss: 0.8538 - reconstruction_loss: 0.7113 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9606 - loss: 0.8536 - reconstruction_loss: 0.7111 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9583 - loss: 0.8532 - reconstruction_loss: 0.7107 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9647 - loss: 0.8524 - reconstruction_loss: 0.7099 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9628 - loss: 0.8520 - reconstruction_loss: 0.7095 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9678 - loss: 0.8520 - reconstruction_loss: 0.7095 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9649 - loss: 0.8517 - reconstruction_loss: 0.7092 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9702 - loss: 0.8522 - reconstruction_loss: 0.7096 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9635 - loss: 0.8521 - reconstruction_loss: 0.7095 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 14.9587 - loss: 0.8511 - reconstruction_loss: 0.7086 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9570 - loss: 0.8504 - reconstruction_loss: 0.7079 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9547 - loss: 0.8507 - reconstruction_loss: 0.7082 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 14.9488 - loss: 0.8502 - reconstruction_loss: 0.7078 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9488 - loss: 0.8505 - reconstruction_loss: 0.7081 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9480 - loss: 0.8500 - reconstruction_loss: 0.7076 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9436 - loss: 0.8486 - reconstruction_loss: 0.7062 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9439 - loss: 0.8495 - reconstruction_loss: 0.7071 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9426 - loss: 0.8490 - reconstruction_loss: 0.7067 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9471 - loss: 0.8498 - reconstruction_loss: 0.7074 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9440 - loss: 0.8501 - reconstruction_loss: 0.7078 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9322 - loss: 0.8490 - reconstruction_loss: 0.7067 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9433 - loss: 0.8494 - reconstruction_loss: 0.7070 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9270 - loss: 0.8479 - reconstruction_loss: 0.7057 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9389 - loss: 0.8498 - reconstruction_loss: 0.7075 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9429 - loss: 0.8500 - reconstruction_loss: 0.7077 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9383 - loss: 0.8472 - reconstruction_loss: 0.7049 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9258 - loss: 0.8481 - reconstruction_loss: 0.7059 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9256 - loss: 0.8484 - reconstruction_loss: 0.7062 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9253 - loss: 0.8475 - reconstruction_loss: 0.7053 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9356 - loss: 0.8488 - reconstruction_loss: 0.7065 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 14.9233 - loss: 0.8485 - reconstruction_loss: 0.7063 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9270 - loss: 0.8486 - reconstruction_loss: 0.7063 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9229 - loss: 0.8475 - reconstruction_loss: 0.7053 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - kl_loss: 14.9233 - loss: 0.8487 - reconstruction_loss: 0.7065 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9228 - loss: 0.8472 - reconstruction_loss: 0.7051 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9160 - loss: 0.8462 - reconstruction_loss: 0.7041 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9128 - loss: 0.8468 - reconstruction_loss: 0.7048 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9160 - loss: 0.8463 - reconstruction_loss: 0.7042 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9114 - loss: 0.8456 - reconstruction_loss: 0.7035 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9148 - loss: 0.8467 - reconstruction_loss: 0.7046 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9148 - loss: 0.8467 - reconstruction_loss: 0.7046 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9143 - loss: 0.8459 - reconstruction_loss: 0.7037 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9238 - loss: 0.8463 - reconstruction_loss: 0.7041 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9095 - loss: 0.8469 - reconstruction_loss: 0.7048 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9142 - loss: 0.8461 - reconstruction_loss: 0.7040 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 14.9050 - loss: 0.8464 - reconstruction_loss: 0.7044 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 14.9085 - loss: 0.8466 - reconstruction_loss: 0.7045 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9026 - loss: 0.8451 - reconstruction_loss: 0.7031 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 14.9037 - loss: 0.8457 - reconstruction_loss: 0.7037 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 1/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - kl_loss: 4.2483 - loss: 3.9997 - reconstruction_loss: 3.9721 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 5.0139 - loss: 1.9475 - reconstruction_loss: 1.6068 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 5.0087 - loss: 1.9223 - reconstruction_loss: 1.5794 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 5.0103 - loss: 1.9121 - reconstruction_loss: 1.5679 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 5.0313 - loss: 1.9071 - reconstruction_loss: 1.5600 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 5.0530 - loss: 1.9013 - reconstruction_loss: 1.5512 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 5.0657 - loss: 1.8991 - reconstruction_loss: 1.5472 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 5.0685 - loss: 1.8971 - reconstruction_loss: 1.5448 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 5.0653 - loss: 1.8947 - reconstruction_loss: 1.5424 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 5.0674 - loss: 1.8938 - reconstruction_loss: 1.5412 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 5.0670 - loss: 1.8923 - reconstruction_loss: 1.5395 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 5.0651 - loss: 1.8924 - reconstruction_loss: 1.5399 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 5.0674 - loss: 1.8906 - reconstruction_loss: 1.5376 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 5.0679 - loss: 1.8898 - reconstruction_loss: 1.5367 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 5.0753 - loss: 1.8891 - reconstruction_loss: 1.5351 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 5.0805 - loss: 1.8875 - reconstruction_loss: 1.5327 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 5.0831 - loss: 1.8871 - reconstruction_loss: 1.5319 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 5.0858 - loss: 1.8868 - reconstruction_loss: 1.5313 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 5.0856 - loss: 1.8857 - reconstruction_loss: 1.5301 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 5.1876 - loss: 1.8759 - reconstruction_loss: 1.5080 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 5.7362 - loss: 1.8076 - reconstruction_loss: 1.3711 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 5.7803 - loss: 1.7924 - reconstruction_loss: 1.3493 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 5.8871 - loss: 1.7739 - reconstruction_loss: 1.3169 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.0183 - loss: 1.7567 - reconstruction_loss: 1.2832 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.2261 - loss: 1.7408 - reconstruction_loss: 1.2424 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.6009 - loss: 1.7073 - reconstruction_loss: 1.1636 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.7043 - loss: 1.6898 - reconstruction_loss: 1.1326 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.7782 - loss: 1.6819 - reconstruction_loss: 1.1156 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.8265 - loss: 1.6740 - reconstruction_loss: 1.1015 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.8452 - loss: 1.6708 - reconstruction_loss: 1.0959 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.8588 - loss: 1.6663 - reconstruction_loss: 1.0894 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.8835 - loss: 1.6636 - reconstruction_loss: 1.0836 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9020 - loss: 1.6612 - reconstruction_loss: 1.0789 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9082 - loss: 1.6576 - reconstruction_loss: 1.0743 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9127 - loss: 1.6569 - reconstruction_loss: 1.0729 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9146 - loss: 1.6549 - reconstruction_loss: 1.0705 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9176 - loss: 1.6521 - reconstruction_loss: 1.0671 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9228 - loss: 1.6526 - reconstruction_loss: 1.0670 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9210 - loss: 1.6506 - reconstruction_loss: 1.0650 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9212 - loss: 1.6491 - reconstruction_loss: 1.0633 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 6.9261 - loss: 1.6498 - reconstruction_loss: 1.0636 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9197 - loss: 1.6469 - reconstruction_loss: 1.0610 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9240 - loss: 1.6469 - reconstruction_loss: 1.0605 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - kl_loss: 6.9250 - loss: 1.6454 - reconstruction_loss: 1.0588 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9274 - loss: 1.6450 - reconstruction_loss: 1.0581 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9264 - loss: 1.6439 - reconstruction_loss: 1.0570 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9295 - loss: 1.6445 - reconstruction_loss: 1.0573 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9306 - loss: 1.6442 - reconstruction_loss: 1.0569 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9287 - loss: 1.6428 - reconstruction_loss: 1.0555 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9283 - loss: 1.6427 - reconstruction_loss: 1.0554 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9337 - loss: 1.6427 - reconstruction_loss: 1.0548 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9298 - loss: 1.6409 - reconstruction_loss: 1.0533 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9303 - loss: 1.6413 - reconstruction_loss: 1.0536 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9342 - loss: 1.6418 - reconstruction_loss: 1.0538 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9306 - loss: 1.6396 - reconstruction_loss: 1.0517 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9326 - loss: 1.6387 - reconstruction_loss: 1.0505 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9349 - loss: 1.6395 - reconstruction_loss: 1.0511 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9365 - loss: 1.6407 - reconstruction_loss: 1.0522 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9392 - loss: 1.6397 - reconstruction_loss: 1.0508 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9373 - loss: 1.6377 - reconstruction_loss: 1.0489 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9394 - loss: 1.6391 - reconstruction_loss: 1.0502 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9387 - loss: 1.6378 - reconstruction_loss: 1.0488 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9391 - loss: 1.6396 - reconstruction_loss: 1.0508 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9363 - loss: 1.6374 - reconstruction_loss: 1.0486 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9365 - loss: 1.6379 - reconstruction_loss: 1.0492 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9410 - loss: 1.6380 - reconstruction_loss: 1.0488 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 6.9397 - loss: 1.6373 - reconstruction_loss: 1.0481 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9400 - loss: 1.6369 - reconstruction_loss: 1.0477 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9400 - loss: 1.6368 - reconstruction_loss: 1.0476 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 6.9390 - loss: 1.6368 - reconstruction_loss: 1.0477 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9421 - loss: 1.6361 - reconstruction_loss: 1.0466 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9396 - loss: 1.6354 - reconstruction_loss: 1.0461 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9419 - loss: 1.6355 - reconstruction_loss: 1.0460 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9392 - loss: 1.6339 - reconstruction_loss: 1.0444 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9378 - loss: 1.6338 - reconstruction_loss: 1.0445 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9397 - loss: 1.6349 - reconstruction_loss: 1.0455 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9421 - loss: 1.6344 - reconstruction_loss: 1.0446 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9409 - loss: 1.6352 - reconstruction_loss: 1.0457 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 6.9430 - loss: 1.6338 - reconstruction_loss: 1.0439 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9392 - loss: 1.6341 - reconstruction_loss: 1.0446 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9386 - loss: 1.6329 - reconstruction_loss: 1.0434 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9420 - loss: 1.6338 - reconstruction_loss: 1.0439 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9440 - loss: 1.6338 - reconstruction_loss: 1.0438 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9421 - loss: 1.6329 - reconstruction_loss: 1.0430 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9387 - loss: 1.6325 - reconstruction_loss: 1.0429 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9394 - loss: 1.6326 - reconstruction_loss: 1.0429 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9383 - loss: 1.6317 - reconstruction_loss: 1.0420 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9423 - loss: 1.6335 - reconstruction_loss: 1.0436 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9375 - loss: 1.6318 - reconstruction_loss: 1.0423 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9371 - loss: 1.6328 - reconstruction_loss: 1.0434 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.9377 - loss: 1.6314 - reconstruction_loss: 1.0418 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9395 - loss: 1.6313 - reconstruction_loss: 1.0415 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9418 - loss: 1.6326 - reconstruction_loss: 1.0426 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9373 - loss: 1.6299 - reconstruction_loss: 1.0402 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9379 - loss: 1.6305 - reconstruction_loss: 1.0408 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 6.9409 - loss: 1.6311 - reconstruction_loss: 1.0412 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8ms/step - kl_loss: 6.9395 - loss: 1.6314 - reconstruction_loss: 1.0416 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - kl_loss: 6.9445 - loss: 1.6321 - reconstruction_loss: 1.0418 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8ms/step - kl_loss: 6.9408 - loss: 1.6317 - reconstruction_loss: 1.0418 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8ms/step - kl_loss: 6.9375 - loss: 1.6288 - reconstruction_loss: 1.0390 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 1/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 23ms/step - kl_loss: 5.3624e-04 - loss: 5.3624e-04 - reconstruction_loss: 36.5500 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 1.2378e-07 - loss: 1.2378e-07 - reconstruction_loss: 36.5309 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.6892e-09 - loss: 6.6892e-09 - reconstruction_loss: 36.5258 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 1.1805e-09 - loss: 1.1805e-09 - reconstruction_loss: 36.5384 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 2.6280e-10 - loss: 2.6280e-10 - reconstruction_loss: 36.5382 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 7.8353e-12 - loss: 7.8353e-12 - reconstruction_loss: 36.5450 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 1.8518e-11 - loss: 1.8518e-11 - reconstruction_loss: 36.5324 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 1.4850e-12 - loss: 1.4850e-12 - reconstruction_loss: 36.5440 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 2.4586e-11 - loss: 2.4586e-11 - reconstruction_loss: 36.5434 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.2867e-12 - loss: 6.2867e-12 - reconstruction_loss: 36.5272 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 9.3801e-12 - loss: 9.3801e-12 - reconstruction_loss: 36.5243 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - kl_loss: 2.2688e-12 - loss: 2.2688e-12 - reconstruction_loss: 36.5391 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 1.2956e-11 - loss: 1.2956e-11 - reconstruction_loss: 36.5415 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 3.2799e-11 - loss: 3.2799e-11 - reconstruction_loss: 36.5418 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 2.7195e-12 - loss: 2.7195e-12 - reconstruction_loss: 36.5346 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 2.2521e-11 - loss: 2.2521e-11 - reconstruction_loss: 36.5399 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 4.6008e-11 - loss: 4.6008e-11 - reconstruction_loss: 36.5330 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 4.3208e-11 - loss: 4.3208e-11 - reconstruction_loss: 36.5369 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 3.5721e-11 - loss: 3.5721e-11 - reconstruction_loss: 36.5351 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 9.4972e-11 - loss: 9.4972e-11 - reconstruction_loss: 36.5355 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 9.1590e-11 - loss: 9.1590e-11 - reconstruction_loss: 36.5253 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 3.5124e-11 - loss: 3.5124e-11 - reconstruction_loss: 36.5320 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 7.2748e-11 - loss: 7.2748e-11 - reconstruction_loss: 36.5322 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.0786e-11 - loss: 6.0786e-11 - reconstruction_loss: 36.5513 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 3.5662e-11 - loss: 3.5662e-11 - reconstruction_loss: 36.5439 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.2068e-11 - loss: 6.2068e-11 - reconstruction_loss: 36.5568 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 9.4946e-11 - loss: 9.4946e-11 - reconstruction_loss: 36.5441 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 7.5630e-11 - loss: 7.5630e-11 - reconstruction_loss: 36.5359 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - kl_loss: 2.4587e-11 - loss: 2.4587e-11 - reconstruction_loss: 36.5393 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 3.3673e-11 - loss: 3.3673e-11 - reconstruction_loss: 36.5353 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 4.0838e-11 - loss: 4.0838e-11 - reconstruction_loss: 36.5391 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 1.0410e-10 - loss: 1.0410e-10 - reconstruction_loss: 36.5288 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 4.8123e-11 - loss: 4.8123e-11 - reconstruction_loss: 36.5374 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 2.4146e-11 - loss: 2.4146e-11 - reconstruction_loss: 36.5409 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 2.7566e-11 - loss: 2.7566e-11 - reconstruction_loss: 36.5392 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 4.5995e-11 - loss: 4.5995e-11 - reconstruction_loss: 36.5280 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 6.5076e-11 - loss: 6.5076e-11 - reconstruction_loss: 36.5373 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - kl_loss: 5.3910e-11 - loss: 5.3910e-11 - reconstruction_loss: 36.5414 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 3.7140e-11 - loss: 3.7140e-11 - reconstruction_loss: 36.5325 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 4.0249e-11 - loss: 4.0249e-11 - reconstruction_loss: 36.5262 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 2.4505e-11 - loss: 2.4505e-11 - reconstruction_loss: 36.5334 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 3.1384e-11 - loss: 3.1384e-11 - reconstruction_loss: 36.5412 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 5.2477e-11 - loss: 5.2477e-11 - reconstruction_loss: 36.5284 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.7318e-11 - loss: 6.7318e-11 - reconstruction_loss: 36.5480 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 3.4862e-11 - loss: 3.4862e-11 - reconstruction_loss: 36.5302 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8ms/step - kl_loss: 1.0289e-10 - loss: 1.0289e-10 - reconstruction_loss: 36.5355 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 3.2018e-11 - loss: 3.2018e-11 - reconstruction_loss: 36.5511 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 1.0018e-10 - loss: 1.0018e-10 - reconstruction_loss: 36.5471 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 6.9907e-11 - loss: 6.9907e-11 - reconstruction_loss: 36.5249 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 3.0948e-11 - loss: 3.0948e-11 - reconstruction_loss: 36.5528 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - kl_loss: 3.1305e-11 - loss: 3.1305e-11 - reconstruction_loss: 36.5378 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 4.3124e-11 - loss: 4.3124e-11 - reconstruction_loss: 36.5422 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 7.4921e-12 - loss: 7.4921e-12 - reconstruction_loss: 36.5501 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 4.6252e-11 - loss: 4.6252e-11 - reconstruction_loss: 36.5443 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 1.3770e-11 - loss: 1.3770e-11 - reconstruction_loss: 36.5343 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 7.0091e-11 - loss: 7.0091e-11 - reconstruction_loss: 36.5363 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 3.4216e-11 - loss: 3.4216e-11 - reconstruction_loss: 36.5322 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 9ms/step - kl_loss: 7.7650e-12 - loss: 7.7650e-12 - reconstruction_loss: 36.5357 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 5.2270e-11 - loss: 5.2270e-11 - reconstruction_loss: 36.5357 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8ms/step - kl_loss: 5.7539e-11 - loss: 5.7539e-11 - reconstruction_loss: 36.5409 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 7.4416e-12 - loss: 7.4416e-12 - reconstruction_loss: 36.5403 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 9.0553e-11 - loss: 9.0553e-11 - reconstruction_loss: 36.5505 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 4.2364e-11 - loss: 4.2364e-11 - reconstruction_loss: 36.5477 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.1145e-12 - loss: 6.1145e-12 - reconstruction_loss: 36.5482 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 1.0652e-11 - loss: 1.0652e-11 - reconstruction_loss: 36.5301 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 5.9418e-11 - loss: 5.9418e-11 - reconstruction_loss: 36.5260 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 5.6573e-11 - loss: 5.6573e-11 - reconstruction_loss: 36.5493 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8ms/step - kl_loss: 5.5689e-11 - loss: 5.5689e-11 - reconstruction_loss: 36.5354 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - kl_loss: 4.4945e-11 - loss: 4.4945e-11 - reconstruction_loss: 36.5402 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 4.3334e-11 - loss: 4.3334e-11 - reconstruction_loss: 36.5362 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 4.3235e-11 - loss: 4.3235e-11 - reconstruction_loss: 36.5329 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 3.7395e-11 - loss: 3.7395e-11 - reconstruction_loss: 36.5363 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 7.0745e-11 - loss: 7.0745e-11 - reconstruction_loss: 36.5366 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 8.6182e-11 - loss: 8.6182e-11 - reconstruction_loss: 36.5366 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 1.7990e-11 - loss: 1.7990e-11 - reconstruction_loss: 36.5389 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 3.5701e-11 - loss: 3.5701e-11 - reconstruction_loss: 36.5205 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 3.3111e-11 - loss: 3.3111e-11 - reconstruction_loss: 36.5366 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.5723e-11 - loss: 6.5723e-11 - reconstruction_loss: 36.5291 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 6.1498e-11 - loss: 6.1498e-11 - reconstruction_loss: 36.5272 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 5.1491e-11 - loss: 5.1491e-11 - reconstruction_loss: 36.5460 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 7.6100e-11 - loss: 7.6100e-11 - reconstruction_loss: 36.5450 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 2.2215e-11 - loss: 2.2215e-11 - reconstruction_loss: 36.5398 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 5.6903e-11 - loss: 5.6903e-11 - reconstruction_loss: 36.5420 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 4.5482e-11 - loss: 4.5482e-11 - reconstruction_loss: 36.5486 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 7.5914e-11 - loss: 7.5914e-11 - reconstruction_loss: 36.5438 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 3.6464e-11 - loss: 3.6464e-11 - reconstruction_loss: 36.5381 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 8.6232e-11 - loss: 8.6232e-11 - reconstruction_loss: 36.5393 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 3.1599e-11 - loss: 3.1599e-11 - reconstruction_loss: 36.5355 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 1.3290e-10 - loss: 1.3290e-10 - reconstruction_loss: 36.5338 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8ms/step - kl_loss: 7.0838e-11 - loss: 7.0838e-11 - reconstruction_loss: 36.5530 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 3.8782e-11 - loss: 3.8782e-11 - reconstruction_loss: 36.5370 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8ms/step - kl_loss: 4.6762e-11 - loss: 4.6762e-11 - reconstruction_loss: 36.5336 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 8ms/step - kl_loss: 4.6227e-11 - loss: 4.6227e-11 - reconstruction_loss: 36.5359 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8ms/step - kl_loss: 6.6647e-11 - loss: 6.6647e-11 - reconstruction_loss: 36.5449 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - kl_loss: 4.7280e-11 - loss: 4.7280e-11 - reconstruction_loss: 36.5383 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 9ms/step - kl_loss: 4.4843e-13 - loss: 4.4843e-13 - reconstruction_loss: 36.5470 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8ms/step - kl_loss: 4.9056e-11 - loss: 4.9056e-11 - reconstruction_loss: 36.5478 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 3.5838e-11 - loss: 3.5838e-11 - reconstruction_loss: 36.5525 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9ms/step - kl_loss: 1.7263e-11 - loss: 1.7263e-11 - reconstruction_loss: 36.5433 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m6569/6569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - kl_loss: 4.4243e-11 - loss: 4.4243e-11 - reconstruction_loss: 36.5442 - val_kl_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# Iterate e-3 to e0\n",
    "for i in np.logspace(-3, 0, 4):\n",
    "    path = '/Code/Replicate/Models'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    epochs = 100\n",
    "    batch_size = 1024\n",
    "\n",
    "    cnn_vae = train_cnn_vae(train, val, epochs=epochs, batch_size=batch_size, beta=i)\n",
    "\n",
    "    #cnn_vae.save(f'{path}/full_cnn_vae_beta{i}.keras')\n",
    "    tmp = CNN_VAE(eta_b=eta_b, phi_b=phi_b, beta=i\n",
    "            )\n",
    "    tmp.set_weights(cnn_vae.get_weights())\n",
    "    tmp.save(f'{path}/full_cnn_vae_beta{i}.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
