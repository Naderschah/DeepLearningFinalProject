{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VuVfkKG1XOS"
      },
      "source": [
        "# Replication\n",
        "\n",
        "I cant find model weights, only the layers of the final quanitzed model\n",
        "\n",
        "Instead I will replicate the architecture and the way training data was split etc\n",
        "\n",
        "Training Input is everything except classification\n",
        "\n",
        "Data is scaled in the following ways:\n",
        "- pT ([:,:,0]) Is z-scaled (x - mean)/std : They say they bring all to O(1) but not how so this seems reasonable\n",
        "- eta and phi are tanh scaled : tanh(x / x_b) where x_b is the max(abs(x)) for non padded entries : This is only done before the MSE loss, implementing this for KL is very non trivial\n",
        "\n",
        "Models are constructed as classes with the encoder and decoder created as submodels\n",
        "\n",
        "So if we have a full model say CNN_VAE we access the encoder with either CNN_VAE.layers[0] or CNN_VAE.get_layer(\"cnn_encoder\"), but check what the actual name is, the submodel extracted then has the same methods available\n",
        "\n",
        "The MSE loss and masked MSE loss is handled as functions that require a partial to work due to the way tensorflow works\n",
        "\n",
        "The beta parameter managing the balance between MSE and KL is not defined in the paper -> A number of values are trialed and the best is selected -> Note that this is non exhaustive of a search and only done to order of magnitude not to exact value\n",
        "\n",
        "Also note that if you run this and an error occurs during any step whatsoever you will likely have to restart the kernel as I am now convinced that this causes Memory leaks either due to jupyter loosing the reference or tensorflow handling the reference in an odd fashion -> I would like to blame tensorflow rather than jupyter\n",
        "\n",
        "Misc Notes:\n",
        "\n",
        "When you inevitably run into nan errors dont bother printing things use tf.debugging.enable_check_numerics() instead, this will tell the compiler to raise an exception on nan and inf with a full backtrace on which layer this occured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zL6wRl7O1XOT"
      },
      "outputs": [],
      "source": [
        "# Loss Functions --- Reasoning written out where data is loaded -> Partial needs to be called on these\n",
        "import tensorflow as tf\n",
        "@tf.function\n",
        "def scale_for_MSE(y_true, y_pred, eta_b, phi_b):\n",
        "    \"\"\"\n",
        "    Loss scaling helper\n",
        "    \"\"\"\n",
        "    # Extract\n",
        "    eta_true = y_true[:, :, 1]\n",
        "    phi_true = y_true[:, :, 2]\n",
        "    eta_pred = y_pred[:, :, 1]\n",
        "    phi_pred = y_pred[:, :, 2]\n",
        "    # Apply tanh scaling\n",
        "    eta_true_scaled = tf.tanh(eta_true / eta_b)\n",
        "    phi_true_scaled = tf.tanh(phi_true / phi_b)\n",
        "    eta_pred_scaled = tf.tanh(eta_pred / eta_b)\n",
        "    phi_pred_scaled = tf.tanh(phi_pred / phi_b)\n",
        "    # Replace and hope compilation makes this efficient\n",
        "    y_true_scaled = tf.concat([\n",
        "        y_true[:, :, :1],\n",
        "        eta_true_scaled[:, :, tf.newaxis],\n",
        "        phi_true_scaled[:, :, tf.newaxis],\n",
        "        y_true[:, :, 3:],\n",
        "    ], axis=-1)\n",
        "\n",
        "    y_pred_scaled = tf.concat([\n",
        "        y_pred[:, :, :1],\n",
        "        eta_pred_scaled[:, :, tf.newaxis],\n",
        "        phi_pred_scaled[:, :, tf.newaxis],\n",
        "        y_pred[:, :, 3:],\n",
        "    ], axis=-1)\n",
        "    return y_true_scaled, y_pred_scaled\n",
        "\n",
        "@tf.function\n",
        "def full_MSE(y_true, y_pred, eta_b, phi_b):\n",
        "    \"Full Loss Function overwrite\"\n",
        "    y_true_scaled, y_pred_scaled = scale_for_MSE(y_true, y_pred, eta_b, phi_b)\n",
        "    # Compute MSE\n",
        "    mse = tf.reduce_mean(\n",
        "        tf.reduce_sum(tf.square(y_true_scaled - y_pred_scaled), axis=(1, 2, 3))\n",
        "    )\n",
        "\n",
        "    return mse\n",
        "\n",
        "@tf.function\n",
        "def masked_mse(y_true_og, y_pred_og, eta_b, phi_b, epsilon=1e-12):\n",
        "    \"\"\"\n",
        "    Computes MSE per event, ignoring any zero-padded rows.\n",
        "    Assumes y_true, y_pred each have shape (batch, n_features)\n",
        "    or possibly (batch, H, W, C). Adjust logic as needed.\n",
        "    \"\"\"\n",
        "    y_true, y_pred = scale_for_MSE(y_true_og, y_pred_og, eta_b, phi_b)\n",
        "    # Sum over feature-dims to see whether row is all zeros\n",
        "    row_sum = tf.reduce_sum(tf.abs(y_true), axis=-1)  # shape = (batch,)\n",
        "    # A mask: 1 if non-padded, 0 if padded\n",
        "    mask = tf.cast(row_sum > epsilon, tf.float32)\n",
        "    # Squared error, summation over features\n",
        "    sq_error = tf.reduce_sum(tf.square(y_true - y_pred), axis=-1)  # shape=(batch,)\n",
        "    # Apply mask -> I hate this\n",
        "    sq_error_masked = sq_error * mask\n",
        "    return tf.reduce_sum(sq_error_masked) / tf.reduce_sum(mask)\n",
        "\n",
        "def tmp():\n",
        "    \"\"\"For VAE implementation a lot of code is taken from\n",
        "    https://keras.io/examples/generative/vae/\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import tensorflow as tf\n",
        "    import keras\n",
        "    from keras import ops\n",
        "    from keras import layers\n",
        "    class Sampling(layers.Layer):\n",
        "        \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "        def __init__(self, **kwargs):\n",
        "            super().__init__(**kwargs)\n",
        "            self.seed_generator = keras.random.SeedGenerator(1337)\n",
        "\n",
        "        def call(self, inputs):\n",
        "            z_mean, z_log_var = inputs\n",
        "            batch = ops.shape(z_mean)[0]\n",
        "            dim = ops.shape(z_mean)[1]\n",
        "            epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)\n",
        "            return z_mean + ops.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "    return Sampling\n",
        "Sampling = tmp()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "eLhjtPxD1XOT",
        "outputId": "910667fc-47d1-48d4-90ac-7b7db88e90e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"DNN_Encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DNN_Encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_in (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m3\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ latent (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,435\u001b[0m (9.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,435</span> (9.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,435\u001b[0m (9.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,435</span> (9.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"DNN_Decoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DNN_Decoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_in (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reconstruction (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)                  │           \u001b[38;5;34m1,881\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m3\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reconstruction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,881</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,681\u001b[0m (10.47 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,681</span> (10.47 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,585\u001b[0m (10.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,585</span> (10.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "def dnn_reshape():\n",
        "    \"\"\"Input Space for DNN is flattened\"\"\"\n",
        "    return layers.Flatten()\n",
        "\n",
        "def dnn_encoder(input_dim = 57, latent_dim = 3, name='DNN_Encoder', vae=False):\n",
        "    inputs = tf.keras.Input(shape=(19,3,), name=\"encoder_in\")\n",
        "    x = inputs#layers.BatchNormalization()(inputs)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.Dense(32)(x) # Activation is None By Default\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Dense(16)(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    if vae:\n",
        "        z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "        # Kernel initializer as this term is exponentiated and default init makes the exp -> ooo\n",
        "        z_log_var = layers.Dense(latent_dim, name=\"z_log_var\", kernel_initializer=\"zeros\")(x)\n",
        "        z = Sampling()([z_mean, z_log_var])\n",
        "        return Model(inputs, [z_mean, z_log_var, z], name=name)\n",
        "\n",
        "    latent = layers.Dense(latent_dim, name=\"latent\")(x)\n",
        "\n",
        "    return Model(inputs, latent, name=name)\n",
        "\n",
        "def dnn_decoder(output_dim=57, latent_dim=3, name='DNN_Decoder'):\n",
        "    \"\"\"\n",
        "    BN between Fully connected and activation, last doesnt have activation & BN\n",
        "    \"\"\"\n",
        "    latent_in = tf.keras.Input(shape=(latent_dim,), name=\"decoder_in\")\n",
        "\n",
        "    y = layers.Dense(16)(latent_in)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "    y = layers.LeakyReLU()(y)\n",
        "\n",
        "    y = layers.Dense(32)(y)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "    y = layers.LeakyReLU()(y)\n",
        "\n",
        "    outputs = layers.Dense(output_dim, name=\"reconstruction\")(y)\n",
        "\n",
        "    # And reshape so that the loss works right\n",
        "    outputs = layers.Reshape((19,3,))(outputs)\n",
        "\n",
        "    return Model(latent_in, outputs, name=name)\n",
        "\n",
        "dnn_encoder().summary()\n",
        "dnn_decoder().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vr6lHgpm1XOU"
      },
      "outputs": [],
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "class DNN_AE(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    AE = Encoder -> Decoder, no sampling.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=57, latent_dim=3):\n",
        "        super().__init__()\n",
        "        self.encoder = dnn_encoder(input_dim=input_dim, latent_dim=latent_dim)\n",
        "        self.decoder = dnn_decoder(output_dim=input_dim, latent_dim=latent_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        z = self.encoder(x)            # shape=(batch, latent_dim)\n",
        "        x_recon = self.decoder(z)      # shape=(batch, input_dim)\n",
        "        return x_recon\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class DNN_VAE(tf.keras.Model):\n",
        "    def __init__(self, eta_b, phi_b, input_dim=57, latent_dim=3, beta=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = dnn_encoder(input_dim=input_dim, latent_dim=latent_dim, vae=True)\n",
        "        self.decoder = dnn_decoder(output_dim=input_dim, latent_dim=latent_dim)\n",
        "        self.beta = beta\n",
        "        self.eta_b = eta_b\n",
        "        self.phi_b = phi_b\n",
        "\n",
        "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                masked_mse(data, reconstruction, self.eta_b, self.phi_b)\n",
        "            )\n",
        "\n",
        "            # ✅ KL divergence\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "\n",
        "            # ✅ Total loss with β weighting\n",
        "            total_loss = (1.0 - self.beta) * reconstruction_loss + self.beta * kl_loss\n",
        "\n",
        "        # ✅ Backpropagation\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "        # ✅ Update metrics\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WCvu0vCN1XOU",
        "outputId": "ab930874-1961-4bf5-99ab-ad41a527b134"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"cnn_encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ cnn_encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ zero_padding2d (\u001b[38;5;33mZeroPadding2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m4\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │             \u001b[38;5;34m144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m1,536\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ latent (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m264\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ cnn_encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ zero_padding2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,948\u001b[0m (7.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,948</span> (7.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,946\u001b[0m (7.60 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,946</span> (7.60 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"cnn_decoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_decoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ cnn_decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m576\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m3,104\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ zero_padding2d_1 (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │           \u001b[38;5;34m1,552\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ zero_padding2d_2 (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m145\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ cnn_decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ zero_padding2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ zero_padding2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">145</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,377\u001b[0m (21.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,377</span> (21.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,377\u001b[0m (21.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,377</span> (21.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def build_cnn_encoder(name='cnn_encoder', vae=False):\n",
        "    \"\"\"\n",
        "    Build CNN Encoder\n",
        "    vae : Variational Autoencoder varitation (second final layer)\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(19,3,1), name=\"cnn_encoder_input\")\n",
        "    #      Zeropad to (20,3,1)  - Syntax padding = ((top, bottom), (left, right))\n",
        "    x = layers.ZeroPadding2D(padding=((0,1),(0,0)))(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    #      Block 1  -> Padding valid means no padding\n",
        "    x = layers.Conv2D(16, kernel_size=(3,3), strides=(1,1), padding='valid', use_bias=False)(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.AveragePooling2D(pool_size=(3,1), strides=(3,1))(x)\n",
        "    #      Block 2\n",
        "    x = layers.Conv2D(32, kernel_size=(3,1), strides=(1,1), padding='valid', use_bias=False)(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.AveragePooling2D(pool_size=(3,1), strides=(3,1))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    #      Block 3 - started\n",
        "    if vae:\n",
        "        latent_mean = layers.Dense(8, activation=None, name=\"latent_mean\")(x)\n",
        "        latent_log_var = layers.Dense(8, activation=None, name=\"latent_log_var\", kernel_initializer='zeros')(x)\n",
        "        z = Sampling()([latent_mean, latent_log_var])\n",
        "        return tf.keras.Model(inputs, [latent_mean, latent_log_var, z], name=name)\n",
        "\n",
        "    latent = layers.Dense(8, activation=None, name=\"latent\")(x)\n",
        "    return tf.keras.Model(inputs, latent, name=name)\n",
        "\n",
        "\n",
        "def build_cnn_decoder(name='cnn_decoder'):\n",
        "    \"\"\"\n",
        "    CNN decoder from the paper's bottom figure.\n",
        "    Takes a latent dimension (8) -> Dense -> Reshape -> Conv2DTranspose or Upsampling + Conv2D\n",
        "    to go back to shape (20,3,1) then maybe slice off padding if you want 19,3,1 final.\n",
        "    \"\"\"\n",
        "    #      Block 3 - remainder > Forming encoder input\n",
        "    latent_inputs = tf.keras.Input(shape=(8,), name=\"cnn_decoder_input\")\n",
        "    y = layers.Dense(64, activation=None)(latent_inputs)\n",
        "    y = layers.ReLU()(y)\n",
        "    y = layers.Reshape((2,1,32))(y)\n",
        "    #      Block 4\n",
        "    y = layers.Conv2D(32, kernel_size=(3,1), strides=(3,1), padding='same')(y)\n",
        "    y = layers.ReLU()(y)\n",
        "    y = layers.UpSampling2D(size=(3,1))(y)\n",
        "    y = layers.ZeroPadding2D(padding=((0,0),(1,1)))(y)\n",
        "    #      Block 5\n",
        "    y = layers.Conv2D(16, kernel_size=(3,1), strides=(1,1), padding='same')(y)\n",
        "    y = layers.ReLU()(y)\n",
        "    y = layers.UpSampling2D(size=(3,1))(y)\n",
        "    y = layers.ZeroPadding2D(padding=((1,0),(0,0)))(y)\n",
        "    #      Output\n",
        "    output = layers.Conv2D(1, kernel_size=(3,3), strides=(1,1), padding='valid')(y)\n",
        "\n",
        "    return tf.keras.Model(latent_inputs, output, name=name)\n",
        "\n",
        "build_cnn_encoder().summary()\n",
        "build_cnn_decoder().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ueq8-4SY1XOV"
      },
      "outputs": [],
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "class CNN_AE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = build_cnn_encoder(name=\"cnn_encoder\")\n",
        "        self.decoder = build_cnn_decoder(name=\"cnn_decoder\")\n",
        "\n",
        "    def call(self, x):\n",
        "        z = self.encoder(x)\n",
        "        recon = self.decoder(z)\n",
        "        return recon\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class CNN_VAE(tf.keras.Model):\n",
        "    def __init__(self,eta_b, phi_b, input_shape=(19, 3, 1), latent_dim=3, beta=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = build_cnn_encoder(input_shape=input_shape, latent_dim=latent_dim, vae=True)\n",
        "        self.decoder = build_cnn_decoder(output_shape=input_shape, latent_dim=latent_dim)\n",
        "        self.beta = beta\n",
        "        self.eta_b = eta_b\n",
        "        self.phi_b = phi_b\n",
        "\n",
        "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "\n",
        "\n",
        "            # MSE over all spatial and channel dimensions\n",
        "            #reconstruction_loss = tf.reduce_mean(\n",
        "            #    tf.reduce_sum(tf.square(data - reconstruction), axis=(1, 2, 3))\n",
        "            #)\n",
        "            reconstruction_loss = full_MSE(data , reconstruction, self.eta_b, self.phi_b)\n",
        "\n",
        "            # KL divergence term\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "\n",
        "            # Total loss with β weighting\n",
        "            total_loss = (1.0 - self.beta) * reconstruction_loss + self.beta * kl_loss\n",
        "\n",
        "        # Backprop\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "        # Update\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "WdFCs0Iq1XOV"
      },
      "source": [
        "## Load Data + Define training Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uUAGl5XG1XOW"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from tensorflow.keras.mixed_precision import set_dtype_policy\n",
        "\n",
        "#setting the default evaluation for keras to 16 bit floats, unless more accuracy is necesarry. Is supposed to speed up learning for modern GPU's and TPU's.\n",
        "#All the hls4ml seem to set it to 16bit and i'm guessing there is some built in safety here. See \"https://keras.io/api/mixed_precision/\". Might need to be moved up?\n",
        "set_dtype_policy('mixed_float16')\n",
        "\n",
        "# If you use the dockerfile this should just work\n",
        "#dset = h5py.File('/Code/Dataset/background_for_training.h5', 'r')\n",
        "dset = h5py.File('background_for_training.h5', 'r')\n",
        "dset = {key: dset[key][()] for key in dset.keys()}\n",
        "\"\"\"\n",
        "Contains keys:\n",
        "    Particles_Classes : 4 classes of Particles\n",
        "    Particles_Names : Names of the Particles\n",
        "    Particles : The data (n, 19,4)\n",
        "        19 : Indexes are\n",
        "            - 0 : Missing Transverse Energy\n",
        "            - 1:4 Up to 4 electrons\n",
        "            - 4:8 Up to 4 muons\n",
        "            - 8-18 Up to 10 jets\n",
        "        Subdimension 4 by idx:\n",
        "            - 0 : pT (transverse momentum)\n",
        "            - 1 : eta (pseudorapidity)\n",
        "            - 2 : phi (azimuthal angle)\n",
        "            - 3 : class (0=Nothing, 1=Met,2=electron,3=muon,4=jet)\n",
        "And when something doesnt make sense (ie [:,0,1:4]) its just zero\n",
        "\"\"\"\n",
        "data = dset['Particles']\n",
        "del dset\n",
        "# Do z score norm to aid in training : They dont specify how they made O(1) : And I assume they mean across all defined objects\n",
        "detected_bmap = (data[:,:,3] != 0) # Select defined entries\n",
        "mean_pt = tf.reduce_mean(data[detected_bmap, 0])\n",
        "std_pt = tf.math.reduce_std(data[detected_bmap, 0])\n",
        "data[:,:,0] = ((data[:,:,0] - mean_pt) / std_pt)\n",
        "\n",
        "\"\"\"\n",
        "They mention in the paper:\n",
        "To account for physical boundaries of η and φ, for those features a re-scaled tanh activation is used in the loss computation.\n",
        "\n",
        "So I assume this means we need to find the extent of the parameters (call it b ) and do tanh(x/b) prior to the loss function,\n",
        "I am not sure how one would go about implementing this for KL loss so Im going to do MSE only\n",
        "\"\"\"\n",
        "eta_b = np.maximum(np.max(data[detected_bmap, 1]), np.abs(np.min(data[detected_bmap, 1]))).astype(\"float32\")\n",
        "phi_b = np.maximum(np.max(data[detected_bmap, 2]), np.abs(np.min(data[detected_bmap, 2]))).astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jDTsuQmR1XOW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "train_split = int(0.5*len(data))\n",
        "val_split = int((0.4+0.5)*len(data))\n",
        "\n",
        "n = np.arange(len(data))\n",
        "np.random.shuffle(n)\n",
        "# Do splitting - Dont grab class indices\n",
        "train = data[n[:train_split],          :, :3]\n",
        "val   = data[n[train_split:val_split], :, :3]\n",
        "test  = data[n[val_split:],            :, :3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SLIVEOwH1XOW"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "def train_dnn_ae(x_train, x_val, epochs=100, batch_size=1024):\n",
        "    \"\"\"\n",
        "    Create and train\n",
        "    \"\"\"\n",
        "    # Build\n",
        "    dnn_ae = DNN_AE(\n",
        "        input_dim=57, latent_dim=3\n",
        "        )\n",
        "\n",
        "    # Compile with Adam and masked MSE\n",
        "    loss_func = tf.function(partial(masked_mse, eta_b=eta_b, phi_b=phi_b))\n",
        "    dnn_ae.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=loss_func\n",
        "    )\n",
        "    # Make Callback\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss', patience=10, restore_best_weights=True # restore???\n",
        "        )\n",
        "    ]\n",
        "    # Fit\n",
        "    dnn_ae.fit(\n",
        "        x_train, x_train,\n",
        "        validation_data=(x_val, x_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return dnn_ae\n",
        "\n",
        "def train_dnn_vae(x_train, x_val, epochs=100, batch_size=1024, beta=1.0):\n",
        "    \"\"\"\n",
        "    Create and train\n",
        "    \"\"\"\n",
        "    # Build\n",
        "    dnn_vae = DNN_VAE(eta_b=eta_b, phi_b=phi_b, input_dim=57, latent_dim=3, beta=beta)\n",
        "\n",
        "    # Compile with Adam and masked MSE\n",
        "    dnn_vae.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0),\n",
        "        loss=masked_mse\n",
        "    )\n",
        "    # Make Callback\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss', patience=10, restore_best_weights=True # restore???\n",
        "        )\n",
        "    ]\n",
        "    # Fit\n",
        "    dnn_vae.fit(\n",
        "        x_train,\n",
        "        validation_data=(x_val,),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return dnn_vae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6yx4PyAY1XOW"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "def train_cnn_ae(x_train, x_val,eta_b, phi_b, epochs=100, batch_size=1024):\n",
        "    \"\"\"\n",
        "    Create and train\n",
        "    \"\"\"\n",
        "    cnn_ae_model = CNN_AE(\n",
        "        # No Args\n",
        "    )\n",
        "    loss_func = tf.function(partial(full_MSE, eta_b=eta_b, phi_b=phi_b))\n",
        "    cnn_ae_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=loss_func\n",
        "    )\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss', patience=10, restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        "    cnn_ae_model.fit(\n",
        "        x_train, x_train,\n",
        "        validation_data=(x_val, x_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "    return cnn_ae_model\n",
        "\n",
        "def train_cnn_vae(x_train, x_val, epochs=100, batch_size=1024, beta=1.0):\n",
        "    \"\"\"\n",
        "    Create and train\n",
        "    \"\"\"\n",
        "    cnn_vae_model = CNN_VAE( eta_b=eta_b, phi_b=phi_b, beta=beta )\n",
        "    cnn_vae_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='mse' # I think this is just ignored since we have a custom train loop\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss', patience=10, restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        "    cnn_vae_model.fit(\n",
        "        x_train, x_train,\n",
        "        validation_data=(x_val, x_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return cnn_vae_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnoB19_1XOX"
      },
      "source": [
        "# Actual Training\n",
        "\n",
        "Note that there is a lot of duplicate code as the kernel often doesnt survive past more than one model trainings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph2bGjHq1XOX",
        "outputId": "9bef4dac-ea78-4ad9-a32f-28d7b6a22f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 26ms/step - loss: 0.2965 - val_loss: 0.0577\n",
            "Epoch 2/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - loss: 0.0561 - val_loss: 0.0543\n",
            "Epoch 3/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 27ms/step - loss: 0.0541 - val_loss: 0.0527\n",
            "Epoch 4/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 22ms/step - loss: 0.0524 - val_loss: 0.0474\n",
            "Epoch 5/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 26ms/step - loss: 0.0459 - val_loss: 0.0414\n",
            "Epoch 6/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - loss: 0.0409 - val_loss: 0.0399\n",
            "Epoch 7/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26ms/step - loss: 0.0399 - val_loss: 0.0402\n",
            "Epoch 8/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - loss: 0.0394 - val_loss: 0.0388\n",
            "Epoch 9/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - loss: 0.0388 - val_loss: 0.0382\n",
            "Epoch 10/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0384 - val_loss: 0.0380\n",
            "Epoch 11/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 32ms/step - loss: 0.0381 - val_loss: 0.0390\n",
            "Epoch 12/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - loss: 0.0378 - val_loss: 0.0372\n",
            "Epoch 13/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 22ms/step - loss: 0.0374 - val_loss: 0.0376\n",
            "Epoch 14/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 28ms/step - loss: 0.0370 - val_loss: 0.0371\n",
            "Epoch 15/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - loss: 0.0369 - val_loss: 0.0365\n",
            "Epoch 16/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 26ms/step - loss: 0.0367 - val_loss: 0.0364\n",
            "Epoch 17/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - loss: 0.0363 - val_loss: 0.0359\n",
            "Epoch 18/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - loss: 0.0359 - val_loss: 0.0361\n",
            "Epoch 19/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - loss: 0.0360 - val_loss: 0.0365\n",
            "Epoch 20/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 26ms/step - loss: 0.0359 - val_loss: 0.0369\n",
            "Epoch 21/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26ms/step - loss: 0.0354 - val_loss: 0.0353\n",
            "Epoch 22/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 21ms/step - loss: 0.0354 - val_loss: 0.0353\n",
            "Epoch 23/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 26ms/step - loss: 0.0352 - val_loss: 0.0348\n",
            "Epoch 24/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 27ms/step - loss: 0.0349 - val_loss: 0.0356\n",
            "Epoch 25/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 28ms/step - loss: 0.0351 - val_loss: 0.0348\n",
            "Epoch 26/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 26ms/step - loss: 0.0348 - val_loss: 0.0348\n",
            "Epoch 27/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 26ms/step - loss: 0.0346 - val_loss: 0.0349\n",
            "Epoch 28/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 32ms/step - loss: 0.0345 - val_loss: 0.0344\n",
            "Epoch 29/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 27ms/step - loss: 0.0345 - val_loss: 0.0381\n",
            "Epoch 30/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - loss: 0.0344 - val_loss: 0.0342\n",
            "Epoch 31/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0341 - val_loss: 0.0343\n",
            "Epoch 32/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - loss: 0.0343 - val_loss: 0.0340\n",
            "Epoch 33/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26ms/step - loss: 0.0341 - val_loss: 0.0342\n",
            "Epoch 34/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 21ms/step - loss: 0.0339 - val_loss: 0.0342\n",
            "Epoch 35/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0338 - val_loss: 0.0335\n",
            "Epoch 36/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - loss: 0.0339 - val_loss: 0.0337\n",
            "Epoch 37/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 22ms/step - loss: 0.0337 - val_loss: 0.0335\n",
            "Epoch 38/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 28ms/step - loss: 0.0339 - val_loss: 0.0335\n",
            "Epoch 39/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 23ms/step - loss: 0.0338 - val_loss: 0.0333\n",
            "Epoch 40/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 28ms/step - loss: 0.0334 - val_loss: 0.0334\n",
            "Epoch 41/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - loss: 0.0334 - val_loss: 0.0340\n",
            "Epoch 42/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 26ms/step - loss: 0.0335 - val_loss: 0.0338\n",
            "Epoch 43/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - loss: 0.0334 - val_loss: 0.0331\n",
            "Epoch 44/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 26ms/step - loss: 0.0332 - val_loss: 0.0328\n",
            "Epoch 45/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 22ms/step - loss: 0.0331 - val_loss: 0.0328\n",
            "Epoch 46/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 26ms/step - loss: 0.0330 - val_loss: 0.0335\n",
            "Epoch 47/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - loss: 0.0327 - val_loss: 0.0330\n",
            "Epoch 48/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 28ms/step - loss: 0.0329 - val_loss: 0.0323\n",
            "Epoch 49/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 26ms/step - loss: 0.0325 - val_loss: 0.0323\n",
            "Epoch 50/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 25ms/step - loss: 0.0322 - val_loss: 0.0319\n",
            "Epoch 51/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 21ms/step - loss: 0.0321 - val_loss: 0.0319\n",
            "Epoch 52/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 28ms/step - loss: 0.0320 - val_loss: 0.0322\n",
            "Epoch 53/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 30ms/step - loss: 0.0319 - val_loss: 0.0318\n",
            "Epoch 54/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 22ms/step - loss: 0.0317 - val_loss: 0.0336\n",
            "Epoch 55/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - loss: 0.0319 - val_loss: 0.0312\n",
            "Epoch 56/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - loss: 0.0313 - val_loss: 0.0326\n",
            "Epoch 57/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 21ms/step - loss: 0.0315 - val_loss: 0.0313\n",
            "Epoch 58/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - loss: 0.0313 - val_loss: 0.0311\n",
            "Epoch 59/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 21ms/step - loss: 0.0311 - val_loss: 0.0315\n",
            "Epoch 60/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - loss: 0.0311 - val_loss: 0.0309\n",
            "Epoch 61/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 22ms/step - loss: 0.0310 - val_loss: 0.0309\n",
            "Epoch 62/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0311 - val_loss: 0.0306\n",
            "Epoch 63/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 22ms/step - loss: 0.0309 - val_loss: 0.0315\n",
            "Epoch 64/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 26ms/step - loss: 0.0309 - val_loss: 0.0309\n",
            "Epoch 65/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - loss: 0.0308 - val_loss: 0.0311\n",
            "Epoch 66/100\n",
            "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 22ms/step - loss: 0.0306 - val_loss: 0.0309\n",
            "Epoch 67/100\n",
            "\u001b[1m 180/1954\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 0.0308"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path = '/Code/Replicate/Models'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "epochs = 100\n",
        "batch_size = 1024\n",
        "\n",
        "dnn_ae  = train_dnn_ae( train, val, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "dnn_ae.save(f'{path}/full_dnn_ae.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eEi3sd_1XOX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path = '/Code/Replicate/Models'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "epochs = 100\n",
        "batch_size = 1024\n",
        "\n",
        "cnn_ae  = train_dnn_ae( train, val, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "cnn_ae.save(f'{path}/full_cnn_ae.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RArxXL0J1XOX"
      },
      "source": [
        "# Beta testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94_IwHuC1XOX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Iterate e-3 to e0\n",
        "for i in [1]:#np.logspace(-3, 0, 4):\n",
        "    #The source sited in the paper \"https://openreview.net/pdf?id=Sy2fzU9gl\" talks about beta 1 for vae (and higher?). I think it is sufficient to use 1 for the replica and maybe\n",
        "    #experiment with it in the try things state.\n",
        "    path = '/Code/Replicate/Models'\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    epochs = 100\n",
        "    batch_size = 1024\n",
        "\n",
        "    dnn_vae = train_dnn_vae(train, val, epochs=epochs, batch_size=batch_size, beta=i)\n",
        "\n",
        "    dnn_vae.save(f'{path}/full_dnn_vae_beta{i}.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCZLMQUO1XOX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Iterate e-3 to e0\n",
        "for i in [1]:#np.logspace(-3, 0, 4):\n",
        "    path = '/Code/Replicate/Models'\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    epochs = 100\n",
        "    batch_size = 1024\n",
        "\n",
        "    cnn_vae = train_cnn_vae(train, val, epochs=epochs, batch_size=batch_size, beta=i)\n",
        "\n",
        "    cnn_vae.save(f'{path}/full_cnn_vae_beta{i}.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTDtUGC_1XOY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}